<!DOCTYPE html><html lang="en"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="utf-8"><title>NB and LR | Zeyan LI&#39;s Homepage</title><meta name="keywords" content="NB and LR"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="description" content="Naive Bayesian and Logistic Regression"><meta property="og:type" content="article"><meta property="og:title" content="NB and LR"><meta property="og:url" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/index.html"><meta property="og:site_name" content="Zeyan LI&#39;s Homepage"><meta property="og:description" content="Naive Bayesian and Logistic Regression"><meta property="og:locale" content="en"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190418201126654.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190418212303876.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190418213726821.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419102050758.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419102100816.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419104811404.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419104825706.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419104845782.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419104916055.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419110333901.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419111147456.png"><meta property="og:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190419112607927.png"><meta property="og:updated_time" content="2020-03-27T09:10:54.096Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="NB and LR"><meta name="twitter:description" content="Naive Bayesian and Logistic Regression"><meta name="twitter:image" content="https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/image-20190418201126654.png"><link rel="icon" href="/img/chitanta.png"><link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css"><link rel="stylesheet" href="/libs/open-sans/styles.css"><link rel="stylesheet" href="/libs/source-code-pro/styles.css"><link rel="stylesheet" href="/css/style.css"><script src="/libs/jquery/2.1.3/jquery.min.js"></script><script src="/libs/jquery/plugins/cookie/1.4.1/jquery.cookie.js"></script><link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css"><link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css"><script type="text/javascript">!function(e,a,t,n,g,c,o){e.GoogleAnalyticsObject="ga",e.ga=e.ga||function(){(e.ga.q=e.ga.q||[]).push(arguments)},e.ga.l=1*new Date,c=a.createElement(t),o=a.getElementsByTagName(t)[0],c.async=1,c.src="//www.google-analytics.com/analytics.js",o.parentNode.insertBefore(c,o)}(window,document,"script"),ga("create","UA-138651056-1","auto"),ga("send","pageview")</script></head></html><body><div id="container"><header id="header"><div id="header-main" class="header-inner"><div class="outer"><a href="/" id="logo"><span class="site-title">Zeyan LI&#39;s Homepage</span></a><nav id="main-nav"><a class="main-nav-link" href="/">Home</a> <a class="main-nav-link" href="/archives">Archives</a> <a class="main-nav-link" href="/categories">Categories</a> <a class="main-nav-link" href="/tags">Tags</a> <a class="main-nav-link" href="/">About</a></nav><nav id="sub-nav"><div class="profile" id="profile-nav"><a id="profile-anchor" href="javascript:;"><img class="avatar" src="https://www.gravatar.com/avatar/07d6dce3cbd35d7c566b5f53f05dba2d"> <i class="fa fa-caret-down"></i></a></div></nav><div id="search-form-wrap"><form class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"> <button type="submit" class="search-form-submit"></button></form><div class="ins-search"><div class="ins-search-mask"></div><div class="ins-search-container"><div class="ins-input-wrapper"><input type="text" class="ins-search-input" placeholder="Type something..."> <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span></div><div class="ins-section-wrapper"><div class="ins-section-container"></div></div></div></div><script>window.INSIGHT_CONFIG={TRANSLATION:{POSTS:"Posts",PAGES:"Pages",CATEGORIES:"Categories",TAGS:"Tags",UNTITLED:"(Untitled)"},ROOT_URL:"/",CONTENT_URL:"/content.json"}</script><script src="/js/insight.js"></script></div></div></div><div id="main-nav-mobile" class="header-sub header-inner"><table class="menu outer"><tr><td><a class="main-nav-link" href="/">Home</a></td><td><a class="main-nav-link" href="/archives">Archives</a></td><td><a class="main-nav-link" href="/categories">Categories</a></td><td><a class="main-nav-link" href="/tags">Tags</a></td><td><a class="main-nav-link" href="/">About</a></td><td><div class="search-form"><input type="text" class="ins-search-input search-form-input" placeholder="Search"></div></td></tr></table></div></header><div class="outer"><aside id="profile"><div class="inner profile-inner"><div class="base-info profile-block"><img id="avatar" src="https://www.gravatar.com/avatar/07d6dce3cbd35d7c566b5f53f05dba2d?s=128"><h2 id="name">Zeyan LI</h2><h3 id="title">Ph.D. student</h3><span id="location"><i class="fa fa-map-marker"></i>Beijing, China</span> <a id="follow" target="_blank" href="https://github.com/lizeyan/">FOLLOW</a></div><div class="article-info profile-block"><div class="article-info-block">38 <span>posts</span></div><div class="article-info-block">3 <span>tags</span></div></div><div class="profile-block social-links"><table><tr><td><a href="https://github.com/lizeyan/" target="_blank" title="github" class="tooltip"><i class="fa fa-github"></i></a></td></tr></table></div></div></aside><aside id="sidebar"><div class="widget-wrap" id="categories"><h3 class="widget-title"><span>categories</span> &nbsp; <a id="allExpand" href="#"><i class="fa fa-angle-double-down fa-2x"></i></a></h3><ul class="unstyled" id="tree"><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Algorithm</a><ul class="unstyled" id="tree"><li class="file"><a href="/Algorithm/PC_algorithm/">PC Algorithm</a></li><li class="file"><a href="/Algorithm/association_rule_mining/">Association Rule Mining</a></li><li class="file"><a href="/Algorithm/locality_sensitive_hash/">Locality Sensitive Hashing</a></li><li class="file"><a href="/Algorithm/pagerank/">Page Rank</a></li><li class="file"><a href="/Algorithm/sequential_pattern_mining/">Sequential Pattern Mining</a></li><li class="file"><a href="/Algorithm/tsne/">t-SNE</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Conference</a><ul class="unstyled" id="tree"><li class="file"><a href="/Conference/ISSRE/"></a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; DeepLearningBook</a><ul class="unstyled" id="tree"><li class="file"><a href="/DeepLearningBook/optimization/">Optimization</a></li><li class="file"><a href="/DeepLearningBook/regularization/">Regularization</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Dreaming Dogs</a><ul class="unstyled" id="tree"><li class="file"><a href="/Dreaming Dogs/What is Dreaming Dogs/">Dreaming Dogs</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Latex</a><ul class="unstyled" id="tree"><li class="file"><a href="/Latex/cjk/">cjk</a></li><li class="file"><a href="/Latex/latex_snippets/">LaTex Snippets</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Linux</a><ul class="unstyled" id="tree"><li class="file"><a href="/Linux/bash_redirect_output/">Bash Redirect Output</a></li><li class="file"><a href="/Linux/ubuntu_1804_install_notes/">Ubuntu 18.04 install notes</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; PaperNotes</a><ul class="unstyled" id="tree"><li class="file"><a href="/PaperNotes/gan/">GAN</a></li><li class="file"><a href="/PaperNotes/gan_anomaly_detection/">GAN Anomaly Detection</a></li><li class="file"><a href="/PaperNotes/network_diffusion/">Network Diffusion</a></li><li class="file"><a href="/PaperNotes/train_gan/">Train GAN</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Proxmox Virtual Environment</a><ul class="unstyled" id="tree"><li class="file"><a href="/Proxmox Virtual Environment/unable_to_access_host/">Unable to Access Host via PVE API</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Python</a><ul class="unstyled" id="tree"><li class="file"><a href="/Python/Einstein-Summation-Convention/">Einstein Summation Convention</a></li></ul></li><li class="directory open"><a href="#" data-role="directory"><i class="fa fa-folder-open"></i> &nbsp; StatisticalMachineLearning</a><ul class="unstyled" id="tree"><li class="file"><a href="/StatisticalMachineLearning/boost/">boost</a></li><li class="file"><a href="/StatisticalMachineLearning/clustering/">Clustering</a></li><li class="file"><a href="/StatisticalMachineLearning/dimension_reduction/">Dimension Reduction</a></li><li class="file"><a href="/StatisticalMachineLearning/kernel_density_estimation/">Kernel Density Estimation</a></li><li class="file active"><a href="/StatisticalMachineLearning/nb_and_lr/">NB and LR</a></li><li class="file"><a href="/StatisticalMachineLearning/reinforcement_learning/">Reinforcement Learning</a></li><li class="file"><a href="/StatisticalMachineLearning/svm/">SVM</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; Statistics</a><ul class="unstyled" id="tree"><li class="file"><a href="/Statistics/test/">Statistical Test</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; configuration</a><ul class="unstyled" id="tree"><li class="file"><a href="/configuration/hexo_config/">Hexo Config</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; macOS</a><ul class="unstyled" id="tree"><li class="file"><a href="/macOS/install_homebrew/">Install Homebrew</a></li><li class="file"><a href="/macOS/install_supervisor/">Install supervisor via brew</a></li><li class="file"><a href="/macOS/macos_unable_to_fork_issue/">macOS Catalina unable to fork issue</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; nginx</a><ul class="unstyled" id="tree"><li class="file"><a href="/nginx/log_format/">log format of nginx</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; pypy</a><ul class="unstyled" id="tree"><li class="file"><a href="/pypy/install_pypy/">install PyPy</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; seafile</a><ul class="unstyled" id="tree"><li class="file"><a href="/seafile/client_conflicts/">Fix 'there is a conflict with an existing library'</a></li></ul></li><li class="directory"><a href="#" data-role="directory"><i class="fa fa-folder"></i> &nbsp; 日本語</a><ul class="unstyled" id="tree"><li class="file"><a href="/日本語/キセキ/">キセキ</a></li><li class="file"><a href="/日本語/本文/">本文</a></li><li class="file"><a href="/日本語/用言/">用言</a></li></ul></li></ul></div><script>$(document).ready(function(){var r="fa-folder-open",i="fa-folder",l="fa-angle-double-down",d="fa-angle-double-up";$(document).on("click",'#categories a[data-role="directory"]',function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul");e.removeClass(r).removeClass(i),s?(void 0!==l&&l.slideUp({duration:100}),e.addClass(i)):(void 0!==l&&l.slideDown({duration:100}),e.addClass(r))}),$('#categories a[data-role="directory"]').bind("contextmenu",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(r),l=$(this).siblings("ul"),d=$.merge(l.find("li ul"),l),o=$.merge(l.find(".fa"),e);o.removeClass(r).removeClass(i),s?(d.slideUp({duration:100}),o.addClass(i)):(d.slideDown({duration:100}),o.addClass(r))}),$(document).on("click","#allExpand",function(a){a.preventDefault();var e=$(this).children(".fa"),s=e.hasClass(l);e.removeClass(l).removeClass(d),s?($("#sidebar .fa.fa-folder").removeClass("fa-folder").addClass("fa-folder-open"),$("#categories li ul").slideDown({duration:100}),e.addClass(d)):($("#sidebar .fa.fa-folder-open").removeClass("fa-folder-open").addClass("fa-folder"),$("#categories li ul").slideUp({duration:100}),e.addClass(l))})})</script><div id="toTop" class="fa fa-angle-up"></div></aside><section id="main"><article id="post-StatisticalMachineLearning/nb_and_lr" class="article article-type-post" itemscope itemprop="blogPost"><div class="article-inner"><header class="article-header"><div class="article-meta"><div class="article-category"><i class="fa fa-folder"></i> <a class="article-category-link" href="/categories/StatisticalMachineLearning/">StatisticalMachineLearning</a></div><div class="article-date"><i class="fa fa-calendar"></i> <a href="/StatisticalMachineLearning/nb_and_lr/"><time datetime="2020-03-27T09:10:54.096Z" itemprop="datePublished">2020-03-27</time></a></div><div class="article-meta-button"><a href="https://github.com/lizeyan/blog/raw/master/source/_posts/StatisticalMachineLearning/nb_and_lr.md">Source</a></div><div class="article-meta-button"><a href="https://github.com/lizeyan/blog/edit/master/source/_posts/StatisticalMachineLearning/nb_and_lr.md">Edit</a></div><div class="article-meta-button"><a href="https://github.com/lizeyan/blog/commits/master/source/_posts/StatisticalMachineLearning/nb_and_lr.md">History</a></div></div><h1 class="article-title" itemprop="name">NB and LR</h1></header><div class="article-entry" itemprop="articleBody"><p>Naive Bayesian and Logistic Regression</p><a id="more"></a><h2 id="nb">NB</h2><h3 id="mle">MLE</h3><h4 id="settings">Settings:</h4><p><span class="math display">\[ p(y|\pi)=\begin{cases}\pi &amp; y=1 \\ 1-\pi &amp; y=0\end{cases} \\ p(x|y, q)=\begin{cases}q_y &amp; x=1 \\ 1-q_y &amp; x=0\end{cases} \]</span></p><p>Log likelihood: <span class="math display">\[ \mathcal{L} = \log \prod_{i=1}^{N}p(x_i, y_i)\\ =\sum_{i=1}^{N}\log p(x_i|y_i)+\log p(y_i) \\ =\sum_{i=1}^{N}x_i\log q_{y_i} + (1-x_i)\log (1 - q_{y_i}) + y_i\log \pi + (1-y_i)\log (1 - \pi) \]</span></p><h4 id="mle-1">MLE</h4><p><span class="math display">\[ \frac{\partial \mathcal{L}}{\partial \pi}=\sum_{i=1}^{N}\frac{1}{\pi}1_{y_i=1}-\frac{1}{1-\pi}1_{y_i=0}\\ =\frac{1}{1-\pi}\sum_{i=1}^{N}\frac{1}{\pi}1_{y_i=1}-1 \]</span></p><p>Therefore <span class="math inline">\(\pi=\frac{N_1}{N}\)</span> <span class="math display">\[ \frac{\partial \mathcal{L}}{\partial q_y}=\sum_{i=1}^{N}1_{y_i=y}(\frac{1}{q_y}1_{x_i=1}-\frac{1}{1-q_y}1_{x_i=0})\\ =\frac{1}{1-q_y}\sum_{i=1}^{N}1_{y_i=y}(\frac{1}{q_y}1_{x_i=1}-1) \]</span> Therefore <span class="math inline">\(q_y=\frac{N_{y, 1}}{N_y}\)</span></p><h4 id="laplace-smoothing">Laplace smoothing</h4><p><span class="math display">\[ \pi=\frac{N_1+\alpha}{N+2\alpha} \]</span></p><h3 id="map">MAP</h3><p><a href="https://en.wikipedia.org/wiki/Conjugate_prior" target="_blank" rel="noopener">Conjugate_prior</a></p><p>Use Beta distribution as the prior <span class="math display">\[ p(q_y)=\frac{\Gamma(\alpha_1+\alpha_2)}{\Gamma(\alpha_1)\Gamma(\alpha_2)}q_y^{\alpha_1-1}(1-q_y)^{\alpha_2-1} \]</span> Now the log likelihood is: <span class="math display">\[ \mathcal{L} = \log p(q_y) + \log \prod_{i=1}^{N}p(x_i, y_i) \\ =\sum_{i=1}^{N}x_i\log q_{y_i} + (1-x_i)\log (1 - q_{y_i}) + y_i\log \pi + (1-y_i)\log (1 - \pi) \\ + (\alpha_1-1)\log q_y+ (\alpha_2-1)\log (1-q_y) \]</span></p><p><span class="math display">\[ \frac{\partial \mathcal{L}}{\partial q_y}=\sum_{i=1}^{N}1_{y_i=y}(\frac{1}{q_y}1_{x_i=1}-\frac{1}{1-q_y}1_{x_i=0})\\ + (\alpha_1-1)\frac{1}{q_y} - (\alpha_2-1)\frac{1}{1-q_y}\\ =\frac{1}{1-q_y}\sum_{i=1}^{N}1_{y_i=y}(\frac{1}{q_y}1_{x_i=1}-1)+ (\alpha_1-1)\frac{1}{q_y} - (\alpha_2-1)\frac{1}{1-q_y} \\ =\frac{1}{1-q_y}(\frac{1}{q_y}N_{y,1}-N_y-\alpha_2+1)+(\alpha_1-1)\frac{1}{q_y} \\ \therefore q_y=\frac{N_{y,1}+\alpha_1-1}{N+\alpha_1+\alpha_2-2} \]</span></p><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190418201126654.png" alt="image-20190418201126654"><figcaption>image-20190418201126654</figcaption></figure><h4 id="beyesian-regression">Beyesian Regression</h4><p>$$ \newcommand{\vv}[1]{\boldsymbol{#1}} y=f(\vv{x})+\epsilon, \epsilon \sim \mathcal{N}(0, \sigma^2) $$ $$ p(\vv{y}|\mathbf{X}, \vv{w})=\prod_{i=1}^{N}p(y_i|\vv{x_i}, \vv{w})=N(X^\top\vv{w}, \sigma^2\mathbf{I}) $$</p><p>Prior is Gaussian <span class="math display">\[ p(\vv{w})=\mathcal{N}(\mathbf{0}, \mathbf{\Sigma}) \]</span> Since the posterior is Gaussian, we only need to determine the mean and covariance. <span class="math display">\[ \text{let } p(\vv{w}|\mathbf{X},\vv{y})=\mathcal{N}(\vv\mu, \mathbf{\Sigma_1})\\ -\frac{1}{2}\sigma^{-2}(\vv{y}^\top\vv{y}-2\vv{y}^\top\mathbf{X}^\top\vv{w}+\vv{w}^\top\mathbf{X}\mathbf{X}^\top\vv{w}+\vv{w}^\top\mathbf{\Sigma}^{-1}\vv{w}) \\ \therefore \mathbf{\Sigma_1}=\mathbf{A}^{-1}, \mathbf{A}=\sigma^{-2}\mathbf{X}\mathbf{X}^\top+\mathbf{\Sigma}^{-1}\\ \therefore \vv{\mu}^\top \mathbf{A}=\sigma^{-2}\vv{y}^\top\mathbf{X}^\top\\ \therefore \vv{\mu}=\sigma^{-2} \mathbf{A}^{-1}\mathbf{X}\vv{y} \]</span> ### Generalized NB</p><p>applied to continious features <span class="math display">\[ Y\sim\text{Bernoulli}(\pi)\\ P(X|Y)=\mathcal{N}(\mu_{Y}, \sigma_{Y}^2) \]</span> The MLE estimated mean and variance is the sample mean variance on those samples with corresponding <span class="math inline">\(Y\)</span>.</p><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190418212303876.png" alt="image-20190418212303876"><figcaption>image-20190418212303876</figcaption></figure><h3 id="decision-boundary-of-nb">Decision Boundary of NB</h3><p>NB's decisiion boundary depends on its distribution assumptions.</p><p>for GNB with equal variance: <span class="math display">\[ \log \frac{\prod_{i=1}^{d}P(X_i|Y_i=0)P(Y_i=0)}{\prod_{i=1}^{d}P(X_i|Y_i=1)P(Y_i=1)}=0 \\ \log \frac{1-\pi}{\pi}+\sum_i \frac{\mu_{i1}^2-\mu_{i0}^2}{\sigma_i^2}+\sum_i\frac{\mu_{i0}-\mu_{i1}}{\sigma_i^2}x_i = 0 \]</span> therefore the decision boundary is linear</p><p>But if the variances are not equal, it is not linear.</p><h2 id="linear-regression">Linear Regression</h2><h3 id="from-nb-to-lr">From NB to LR</h3><p><span class="math display">\[ P(y=1|\vv{x})=\frac{p(y=1, \vv{x})}{p(y=1, \vv{x}) + p(y=0, \vv{x})} \\ =\frac{1}{1+\frac{p(y=0, \vv{x})}{p(y=1, \vv{x})}} \\ =\frac{1}{1+\exp(-\vv{w}^\top\vv{x}-b)} \]</span></p><h4 id="sigmoid-function">sigmoid function</h4><p><span class="math display">\[ \sigma(x)=\frac{1}{1+\exp(-x)}\\ \frac{d\sigma}{dx}=\sigma(x)(1-\sigma(x)) \\ 1-\sigma(x)=\sigma(-x) \]</span></p><h4 id="multiclass-lr">Multiclass LR</h4><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190418213726821.png" alt="image-20190418213726821"><figcaption>image-20190418213726821</figcaption></figure><p>decision boundary is not linear, it is piecewise linear</p><h3 id="maximum-conditional-likelihood-estimate">Maximum Conditional Likelihood Estimate</h3><p>MLE is <span class="math inline">\(\max P(X, Y)\)</span>, but we don't have it in LR.</p><p>In MCLE, we do <span class="math inline">\(\max P(Y|X)\)</span></p><h4 id="it-is-a-convex-problem">It is a Convex Problem</h4><p><span class="math display">\[ \mathcal{L}(\vv{w})=\sum_{i=1}^{N}\log p(y_i|\vv{x}_i, \vv{w})\\ =\sum_{i=1}^{N}y_i\vv{w}^\top\vv{x}_i-\log(1+\exp(\vv{w}^\top\vv{x}_i)) \]</span></p><h4 id="gradient-descent">Gradient Descent</h4><p><span class="math display">\[ \frac{\partial \mathcal{L}}{\partial \vv{w}}=\sum_{i=1}^{N}\vv{x}_i(y_i-u_i)\\ u_i=p(y_i=1|\vv{x}_i, \vv{w})=\sigma(-\vv{w}^\top\vv{x}) \]</span></p><p><span class="math display">\[ \vv{w}_{t+1}\leftarrow \vv{w}_t + \frac{\partial \mathcal{L}}{\partial \vv{w}} \]</span></p><h4 id="newton-method">Newton Method</h4><p><span class="math display">\[ \vv{w}_{t+1}\leftarrow \vv{w}_t - \mathbf{H}^{-1}\frac{\partial \mathcal{L}}{\partial \vv{w}}\\ \mathbf{H} = \frac{\partial^2 \mathcal{L}}{\partial\vv{w}\partial\vv{w}} \]</span></p><h4 id="irls">IRLS</h4><p><span class="math display">\[ \nabla_\vv{w}\mathcal{L}=\sum_{i=1}^{N}\vv{x}_i(y_i-u_i)=\mathbf{X}(\vv{y}-\vv{u})\\ \mathbf{H}=\nabla^2_\vv{w}\mathcal{L}=\sum_{i=1}^{N}-\vv{x}_iu_i(1-u_i)\vv{x}_i^\top=-\mathbf{X}\mathbf{R}\mathbf{X}^\top \\ \mathbf{R}_{ii}=u_i(1-u_i) \]</span></p><p>For least square of linear regression, we have <span class="math display">\[ \vv{w}=(\mathbf{X}\mathbf{X}^\top)^{-1}\mathbf{X}\vv{y} \]</span> IRLS: <span class="math display">\[ \vv{w}_{t+1}\leftarrow\vv{w}_t - \mathbf{H}^{-1}\nabla_\vv{w}\mathcal{L}\\ =\vv{w}_t-(\mathbf{X}\mathbf{R}\mathbf{X}^\top)^{-1}\mathbf{X}(\vv{u}-\vv{y})\\ =(\mathbf{X}\mathbf{R}\mathbf{X}^\top)^{-1}(\mathbf{X}\mathbf{R}\mathbf{X}^\top\vv{w}_t - \mathbf{X}(\vv{u}-\vv{y}))\\ =(\mathbf{X}\mathbf{R}\mathbf{X}^\top)^{-1}\mathbf{X}\mathbf{R}(\mathbf{X}^\top\vv{w}_t - \mathbf{R}^{-1}(\vv{u}-\vv{y})) \]</span></p><h2 id="generative-v.s.-discrimitive">Generative v.s. Discrimitive</h2><p>Genrative model has assumptions on <span class="math inline">\(P(X|Y)\)</span>, discrimitive models has assumptions on <span class="math inline">\(P(Y|X)\)</span>.</p><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419102050758.png" alt="image-20190419102050758"><figcaption>image-20190419102050758</figcaption></figure><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419102100816.png" alt="image-20190419102100816"><figcaption>image-20190419102100816</figcaption></figure><h2 id="exponential-family">Exponential Family</h2><h3 id="general-form">General Form</h3><p><span class="math display">\[ p(\vv{x}|\vv{\eta})=h(\vv{x})g(\vv{\eta})\exp(\vv\eta^\top\vv u(\vv{x}))\\ =h(\vv{x})\exp(\vv\eta^\top\vv{u}(\vv{x})-A(\vv\eta)) \]</span></p><p><span class="math inline">\(g(\vv\eta)\)</span> is the normalization coefficient.</p><p>More refefence <a href="https://en.wikipedia.org/wiki/Exponential_family" target="_blank" rel="noopener">here</a></p><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419104811404.png" alt="image-20190419104811404"><figcaption>image-20190419104811404</figcaption></figure><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419104825706.png" alt="image-20190419104825706"><figcaption>image-20190419104825706</figcaption></figure><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419104845782.png" alt="image-20190419104845782"><figcaption>image-20190419104845782</figcaption></figure><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419104916055.png" alt="image-20190419104916055"><figcaption>image-20190419104916055</figcaption></figure><h4 id="bernoulli">Bernoulli</h4><p><span class="math display">\[ p(x|\mu)=\mu^{x}(1-\mu)^{1-x} \\ =\exp(x\log\mu+(1-x)\log(1-\mu)) \\ =(1-\mu)\exp(\log\frac{\mu}{1-\mu}x)\\ = \sigma(-\eta)\exp(\eta x) \]</span></p><p><span class="math display">\[ \eta=\log\frac{\mu}{1-\mu}\\ h(x)=1\\ g(\eta)=\sigma(-\eta)\\ u(x)=x \]</span></p><h4 id="multinominal">Multinominal</h4><p><span class="math display">\[ p(\vv{x}|\vv{\mu})=\prod_{k=1}^{M}\mu_k^{x_k}\\ =\exp(\sum x_k\log \mu_k) \\ =\exp(\sum_{i=1}^{M-1}x_k\log \mu_k+(1-\sum_{i=1}^{M-1}x_k)\log(1-\sum_{k=1}^{M-1}\mu_k))\\ =(1-\sum_{i=1}^{M-1}\mu_k)\exp(\sum_{k=1}^{M-1}x_k\log(\frac{\mu_k}{1-\sum_{k=1}^{M-1}\mu_k}))\\ =\frac{(1-\sum_{k=1}^{M-1}\mu_k)}{\mu_M}\exp(\sum_{k=1}^{M}x_k\log\mu_k) \\ =\exp(\sum_{k=1}^{M}x_k\log\mu_k) \]</span></p><p><span class="math display">\[ \vv\eta=(\log \mu_1, \log \mu_2, ..., \log\mu_M)^\top \\ \vv u(\vv{x})=\vv{x}\\ h(\vv{x})=1\\ g(\eta)=1 \]</span></p><h4 id="multivariate-gaussian">Multivariate Gaussian</h4><p><span class="math display">\[ p(\vv{x}|\vv\mu, \mathbf{\Sigma})=\frac{1}{(2\pi)^\frac{d}{2}|\Sigma|^\frac{1}{2}}\exp(-\frac{1}{2}(\vv x - \vv\mu)^\top\Sigma^{-1}(\vv x - \vv\mu))\\ =\frac{1}{(2\pi)^\frac{d}{2}|\Sigma|^\frac{1}{2}}\exp(-\frac{1}{2}\text{tr}(\Sigma^{-1}\vv{x}\vv{x}^\top)+\vv\mu^\top\Sigma^{-1}\vv{x}-\frac{1}{2}\vv\mu^\top\Sigma^{-1}\vv\mu)\\ \]</span></p><p>then <span class="math display">\[ \vv{\eta}=\begin{bmatrix}\Sigma^{-1}\vv{\mu}, -\frac{1}{2}\text{vec}(\Sigma^{-1}) \end{bmatrix} \\ =[\vv\eta_1, \text{vec}(\vv{\eta}_2)]\\ \vv{u}(\vv{x})=\begin{bmatrix}\vv{x}, \text{vec}(\vv{x}\vv{x}^\top)\end{bmatrix} \]</span></p><p><span class="math display">\[ g(\vv{\eta})=|\Sigma|^{-\frac{1}{2}}\exp(-\frac{1}{2}\vv\mu^\top\Sigma^{-1}\vv{\mu})\\ =|-2\vv{\eta}_2|^{\frac{1}{2}}\exp(-\frac{1}{2}((-2\vv\eta_2)^{-1}\vv\eta_1)^\top\vv\eta_1)\\ =|-2\vv{\eta}_2|^{\frac{1}{2}}\exp(+\frac{1}{4}\vv\eta_1^\top\vv\eta_2^{-1}\vv\eta_1) \]</span></p><h3 id="why-exponential-family">Why Exponential Family</h3><h4 id="moment">Moment</h4><figure><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419110333901.png" alt="image-20190419110333901"><figcaption>image-20190419110333901</figcaption></figure><p><span class="math display">\[ \because \int_xp(x)=1\\ \therefore\nabla_\eta\int_xh(x)\exp(\eta^\top u(x)-A(\eta))dx=0\\ \therefore\int_x h(x)\exp(\eta^\top u(x)-A(\eta))(u(x)-\nabla_\eta A(\eta))dx=0\\ \therefore \nabla_\eta A(\eta)=\mathbb{E}[u(x)]\\ \because \nabla_\eta^2\int_xh(x)\exp(\eta^\top u(x)-A(\eta))dx=0\\ \therefore \int_x h(x)\exp(\eta^\top u(x)-A(\eta))u^2(x)-h(x)\exp(\eta^\top u(x)-A(\eta))\nabla_n A(\eta) u(x) dx - \nabla_\eta^2 A(\eta)=0\\ \therefore \nabla_\eta^2 A(\eta)=\mathbb{E}[u^2(x)]-(\mathbb{E}[u(x)])^2=\text{Var}[u(x)] \]</span></p><h4 id="mle-for-exponential-falimy-with-i.i.d.-samples">MLE for Exponential Falimy with i.i.d. samples</h4><p><span class="math display">\[ P(D|\vv\eta)=\prod_{i=1}^{N}P(\vv{x}|\vv\eta)\\ =(\prod_{i=1}^{N}h(\vv{x}_i))\exp(\vv\eta^\top\sum_{i=1}^{N}\vv{u}(\vv{x}_i)-NA(\vv\eta)) \]</span></p><p>It is still a exponential family distribution <span class="math display">\[ \nabla_{\vv\eta}\log P=\sum_{i=1}^{N}\vv{u}(\vv{x}_i)-N\nabla_{\eta}A(\vv\eta)\\ \therefore \vv{\mu}=\frac{1}{N}\sum_{i=1}^{N}\vv u(\vv{x}_i) \]</span> <img src="/StatisticalMachineLearning/nb_and_lr/image-20190419111147456.png" alt="image-20190419111147456"></p><h3 id="generailized-linear-models-glim">Generailized Linear Models (GLIM)</h3><p><img src="/StatisticalMachineLearning/nb_and_lr/image-20190419112607927.png" alt="image-20190419112607927"> <span class="math display">\[ \mathbb{E}[y]=u=f(\vv\theta^\top\vv{x}) \]</span></p><p><span class="math display">\[ p(y|\vv{x})=h(\vv u)\exp(\vv\eta^\top \vv u - A(\vv\eta)), \vv u = f(\vv\theta^\top\vv{x}) \]</span></p><p>When <span class="math inline">\(p(y|\vv{x})\)</span> is a bernoulli distribution, <span class="math inline">\(\vv{u}=\sigma(-\vv{w}^\top\vv{x})\)</span>, it is basic linear regression.a <span class="math display">\[ \mathcal{L}=\sum_{n}\log h(\vv u_n)+\sum_n({\vv\eta_n^\top\vv{u}_n-A(\vv\eta_n)})\\ \nabla_\vv\theta\mathcal{L}=\sum_{n}(\vv{u}_n\nabla_{\vv\theta}\vv\eta_n-\vv\mu_n\nabla_{\vv\theta}\vv\eta_n) \]</span></p></div><footer class="article-footer"></footer></div></article><nav id="article-nav"><a href="/StatisticalMachineLearning/svm/" id="article-nav-newer" class="article-nav-link-wrap"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">SVM</div></a><a href="/StatisticalMachineLearning/dimension_reduction/" id="article-nav-older" class="article-nav-link-wrap"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">Dimension Reduction</div></a></nav><script type="text/javascript">!function(){var e=window.location.href,r=document.referrer;if(!/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi.test(e)){var o="//api.share.baidu.com/s.gif";r?(o+="?r="+encodeURIComponent(document.referrer),e&&(o+="&l="+e)):e&&(o+="?l="+e),(new Image).src=o}}(window)</script></section></div><footer id="footer"><div class="outer"><div id="footer-info" class="inner">Zeyan LI &copy; 2020 <a rel="license" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-nd/4.0/80x15.png"></a><br>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>. Theme - <a href="https://github.com/zthxxx/hexo-theme-Wikitten">wikitten</a></div></div></footer><script src="/libs/lightgallery/js/lightgallery.min.js"></script><script src="/libs/lightgallery/js/lg-thumbnail.min.js"></script><script src="/libs/lightgallery/js/lg-pager.min.js"></script><script src="/libs/lightgallery/js/lg-autoplay.min.js"></script><script src="/libs/lightgallery/js/lg-fullscreen.min.js"></script><script src="/libs/lightgallery/js/lg-zoom.min.js"></script><script src="/libs/lightgallery/js/lg-hash.min.js"></script><script src="/libs/lightgallery/js/lg-share.min.js"></script><script src="/libs/lightgallery/js/lg-video.min.js"></script><script src="/libs/justified-gallery/jquery.justifiedGallery.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true,
            TeX: {
                equationNumbers: {
                  autoNumber: 'AMS'
                }
            }
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });</script><script async src="//cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script src="/js/main.js"></script></div></body>