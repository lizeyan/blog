---
title: Optimization
mathjax: true
categories:
  - DeepLearningBook
---

## 8.1 深度学习中的学习和纯优化问题有何不同

机器学习通常不能用直接的方式学习。我们的目标是某个性能指标$P$，但是$P$是和测试集有关的，而且可能本身就是intractable的。为此我们通常是定义一个损失函数$J$，希望优化$J$能够提升$P$。

我们的目标是优化在真实数据分布下的期望损失:

{% raw %}
$$
\newcommand{\vv}[1]{\boldsymbol{#1}}
J^{*}(\vv \theta)=\mathbb{E}_{p_{data}}[\mathcal{L}(f(\vv{x};\vv{\theta}), \vv{y})]
$$

{% endraw %}

### 经验风险

在机器学习问题中，我们是不知道真实数据分布的，我们只有有限个数据样本，这些数据样本的经验分布为$\hat p_{data}$。因此我们只能优化经验风险:
$$
\mathbb{E}_{\vv{x}\sim \hat p_{data}}[\mathcal{L}(f(\vv{x};\vv{\theta}), \vv{y})]
$$


但是经验风险有两个问题：

1.  经验风险容易过拟合。容量足够大的模型往往可以直接记住整个训练集。
2.  常用的高效的优化方法都是基于梯度的。但是准确的损失函数，比如0-1损失函数，往往无法提供梯度。

### 替代损失函数和early stopping

用来替代准确的损失函数，提供梯度信息的损失函数被称为surrogate loss。比如我们一般使用NLL替代0-1损失函数。替代损失函数可能会取得更好的性能，比如在0-1损失已经是0的时候，NLL还可以继续优化。因为即使我们找到了完美的分界面，我们还可以继续优化使得不同类数据分得尽量开。

另一方面的差别是机器学习中一般不会令学习在达到局部极小点才终止。也就是early stopping技术。在验证集上我们可以使用准确的0-1 loss，当验证集上损失不在下降就可以停止训练。在往后训练就会发生过拟合，但此时训练集上梯度往往还比较大。

### minibatch

估计梯度为以下的过程：
$$
\nabla J =\mathbb{E}_{\hat p_{data}}[\nabla \mathcal{L}(f(\vv{x};\vv{\theta}), \vv{y})]
$$
