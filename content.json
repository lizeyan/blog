{"meta":{"title":"Zeyan LI's Homepage","subtitle":"","description":null,"author":"Zeyan LI","url":"https://blog.lizeyan.me","root":"/"},"pages":[{"title":"About Me","date":"2020-03-27T09:10:54.132Z","updated":"2020-03-27T09:10:54.132Z","comments":true,"path":"index.html","permalink":"https://blog.lizeyan.me/index.html","excerpt":"","text":"Zeyan LI 李则言, Ph.D. student at Tsinghua University.Email: li_zeyan@icloud.comGitHub: https://github.com/lizeyanEducationAugust, 2018 -- NowTsinghua University Ph.D., Computer ScienceResearch Focus: network management, software engineeringAt NetMan lab.August, 2014 – June 2018Tsinghua University B.E., Computer SciencePublicationLi, Zeyan, Chengyang Luo, Yiwei Zhao, Yongqian Sun, et al. \"Generic and Robust Localization of Multi-Dimensional Root Causes\". The 30th International Symposium on Software Reliability Engineering (ISSRE 2019). Paper GitHubLi, Zeyan, Wenxiao Chen, and Dan Pei. \"Robust and Unsupervised KPI Anomaly Detection Based on Conditional Variational Autoencoder.\" In 2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC), pp. 1-9. IEEE, 2018. Paper GitHubNan, Guoshun, Xiuquan Qiao, Jiting Wang, Zeyan Li, Jiahao Bu, Changhua Pei, Mengyu Zhou, and Dan Pei. \"The Frame Latency of Personalized Livestreaming Can Be Significantly Slowed Down by WiFi.\" In 2018 IEEE 37th International Performance Computing and Communications Conference (IPCCC), pp. 1-8. IEEE, 2018. PaperXu, Haowen, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu et al. \"Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications.\" In Proceedings of the 2018 World Wide Web Conference, pp. 187-196. International World Wide Web Conferences Steering Committee, 2018. Paper GitHub"},{"title":"Categories","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"categories/index.html","permalink":"https://blog.lizeyan.me/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2020-03-27T09:10:54.132Z","updated":"2020-03-27T09:10:54.132Z","comments":true,"path":"tags/index.html","permalink":"https://blog.lizeyan.me/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Install Homebrew","slug":"macOS/install_homebrew","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"macOS/install_homebrew/","link":"","permalink":"https://blog.lizeyan.me/macOS/install_homebrew/","excerpt":"","text":"在国内用homebrew默认的安装会比较慢123cd ~curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install &gt;&gt; brew_instalvim ~/brew_install对应行修改为：12BREW_REPO = &quot;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.git&quot;.freezeCORE_TAP_REPO = &quot;https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.git&quot;.freeze然后安装完之后1234567cd \"$(brew --repo)\"git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/brew.gitcd \"$(brew --repo)/Library/Taps/homebrew/homebrew-core\"git remote set-url origin https://mirrors.tuna.tsinghua.edu.cn/git/homebrew/homebrew-core.gitbrew update","categories":[{"name":"macOS","slug":"macOS","permalink":"https://blog.lizeyan.me/categories/macOS/"}],"tags":[]},{"title":"Install supervisor via brew","slug":"macOS/install_supervisor","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"macOS/install_supervisor/","link":"","permalink":"https://blog.lizeyan.me/macOS/install_supervisor/","excerpt":"","text":"Install brewGoogle it.Install brew services1brew servicesInstall supervisor1brew install supervisorConfiguration/usr/local/etc/supervisord.ini12345678910111213141516171819;[unix_http_server];file=/usr/local/var/run/supervisor.sock ; the path to the socket file;chmod=0700 ; socket file mode (default 0700);chown=nobody:nogroup ; socket file uid:gid owner;username=user ; default is no username (open server);password=123 ; default is no password (open server)[inet_http_server] ; inet (TCP) server disabled by defaultport=*:9001 ; ip_address:port specifier, *:port for all iface;username=user ; default is no username (open server);password=123 ; default is no password (open server)[supervisorctl];serverurl=unix:///usr/local/var/run/supervisor.sock ; use a unix:// URL for a unix socketserverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris ; should be same as in [*_http_server] if set;password=123 ; should be same as in [*_http_server] if set;prompt=mysupervisor ; cmd line prompt (default &quot;supervisor&quot;);history_file=~/.sc_history ; use readline history if available","categories":[{"name":"macOS","slug":"macOS","permalink":"https://blog.lizeyan.me/categories/macOS/"}],"tags":[]},{"title":"macOS Catalina unable to fork issue","slug":"macOS/macos_unable_to_fork_issue","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"macOS/macos_unable_to_fork_issue/","link":"","permalink":"https://blog.lizeyan.me/macOS/macos_unable_to_fork_issue/","excerpt":"","text":"在macOS X Catalina上，cron进程无法被正常关闭。因为有一个每分钟运行一次的cron job，所有很快就会积累很多进程，超过的系统的最大进程限制。cron进程无法关闭似乎和读写文件有关，将每个cron进程的输出重定向到/dev/null即可1/Users/lizytalk/Projects/blog/keep.sh &amp;&gt; /dev/null","categories":[{"name":"macOS","slug":"macOS","permalink":"https://blog.lizeyan.me/categories/macOS/"}],"tags":[]},{"title":"log format of nginx","slug":"nginx/log_format","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"nginx/log_format/","link":"","permalink":"https://blog.lizeyan.me/nginx/log_format/","excerpt":"","text":"In nginx.conf, we define a log_format called postdata:1234http &#123; log_format postdata &apos;&#123;&quot;ts&quot;: &quot;$time_iso8601&quot;, &quot;status&quot;: $status, &quot;req&quot;: &quot;$uri&quot;, &quot;method&quot;: &quot;$request_method&quot;, &quot;body&quot;: &quot;$request_body&quot;&#125;&apos;; # ...... other content&#125;In site configuration, like site-enabled/default:1234server &#123; access_log /var/log/nginx/access.log postdata; # ...... other content&#125;","categories":[{"name":"nginx","slug":"nginx","permalink":"https://blog.lizeyan.me/categories/nginx/"}],"tags":[]},{"title":"install PyPy","slug":"pypy/install_pypy","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"pypy/install_pypy/","link":"","permalink":"https://blog.lizeyan.me/pypy/install_pypy/","excerpt":"","text":"Install PyPy1pyenv install pypy3.6-7.2.0Install NumPy, Pandas1234apt-get install libblas-dev liblapack-devpip install cythonpip install numpypip install pandasInstall SciPy1apt-get install gfortran pybind11-dev(鳖pip intall pybind11，会导致其他包编译不了，未知原因) or on macOS X12brew install gcc# and then set symbol links by yourself1export MACOSX_DEPLOYMENT_TARGET=10.10export LDFLAGS=\"-L/usr/local/opt/libffi/lib\"export PKG_CONFIG_PATH=\"/usr/local/opt/libffi/lib/pkgconfig\"1pip install \"scipy==1.3.3\"(1.4.0暂时安装不了)","categories":[{"name":"pypy","slug":"pypy","permalink":"https://blog.lizeyan.me/categories/pypy/"}],"tags":[]},{"title":"Fix 'there is a conflict with an existing library'","slug":"seafile/client_conflicts","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"seafile/client_conflicts/","link":"","permalink":"https://blog.lizeyan.me/seafile/client_conflicts/","excerpt":"","text":"http://www.mnott.de/fix-seafile-error-there-is-a-conflict-with-an-existing-library/# Fix SeaFile error “there is a conflict with an existing library”Every now and then I get this error when working with Seafile: “there is a conflict with an existing library.” And just today I found out that I had found a solution three years ago, and since then forgotten about it. So here’s again, for the record, what I did.First of all, I’m working on OSX, and SeaFile client runs against a SQLite database stored in ~/Seafile/.seafile-data/repo.db. To edit that database, I use the sqlite3 command line tool that is available here. Alternatively, you can also use any one SQLite graphical client like SQLite Manager.Anyway. So I cd into that directory:12345&gt; cd ~/Seafile/.seafile-data&gt; sqlite3 repo.db&gt; sqlite&gt; .tables&gt; CommonAncestor GarbageRepos RepoPasswd DeletedRepo MergeInfo RepoProperty FileSyncError Repo RepoTmpToken FolderGroupPerms RepoBranch ServerProperty FolderPermTimestamp RepoKeys FolderUserPerms RepoLanToken&gt;The tables I am interested in is Repo, from which I want to delete an offending repository id. To find the repository ID that I am interested in, I need to use RepoProperty:12&gt; sqlite&gt; SELECT * FROM RepoProperty where value like '%99 -%';07523e5e-5545-4bca-bf71-a971b106392e|worktree|/Users/mnott/Cloud/99 - Shared&gt;The repository that I wanted to re-sync and that gave the error was 99 – Shared, and with the above command I found its repository ID. I then deleted that repository from both the Repo as well as the RepoProperty tables:12&gt; sqlite&gt; delete from repo where repo_id = '07523e5e-5545-4bca-bf71-a971b106392e';sqlite&gt; delete from repoproperty where repo_id = '07523e5e-5545-4bca-bf71-a971b106392e';sqlite&gt; ^D&gt;After that, I quit and restarted the SeaFile client, and I was able to re-sync the repository with its existing folder.Then you should do the same thing in clone.db","categories":[{"name":"seafile","slug":"seafile","permalink":"https://blog.lizeyan.me/categories/seafile/"}],"tags":[]},{"title":"キセキ","slug":"日本語/キセキ","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"日本語/キセキ/","link":"","permalink":"https://blog.lizeyan.me/日本語/キセキ/","excerpt":"","text":"あした きょよりも すきになれる明日 今日よりも 好きになれるあふれる おもいが とまらない溢れる想いが止まらない今まも こんなに好きでいるのにことばにできない言葉に出来ないきみのくれた ヒビが つみかさなり君のくれた日々が積み重なりすぎさったヒビ過ぎ去った日々ふたりあるいたキセキ二人歩いた軌跡ぼくらのであいが もしぐうぜん ならば僕らの出逢いがもし偶然ならばうんめいならば運命ならばきみにめぐりあえた それってキセキ君に巡り会えた それってキセキふたりよりそってあるいて二人寄り添って歩いてとわのあいをかたちにして永遠の愛を形にしていつまでもきみの横でいつまでも君にの横で","categories":[{"name":"日本語","slug":"日本語","permalink":"https://blog.lizeyan.me/categories/日本語/"}],"tags":[]},{"title":"本文","slug":"日本語/本文","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"日本語/本文/","link":"","permalink":"https://blog.lizeyan.me/日本語/本文/","excerpt":"","text":"大学生活私は毎朝６時に起きます。まず顔を洗います。ジョーキングをします。それから、食堂で朝ご飯を食べます。授業は８時に始まります。１２時ごろ友達と昼ご飯を食べます。午後は授業があります。放課後は宿題をします。週に3回くらいパソんコンをします。晩ご飯の後、教室に予習をします。１０時半ごろ、寮に戻ります。寮は４人部屋です。時々ラジオで音楽を聴きます。消灯は１１時です。土曜と日曜は休みです。土曜日の午前中は洗濯をします。午後は家庭教師のアルバイトをします。高校生に英語を教えます。日曜日はよく部屋でギターを弾きます。友人との一日王梅芳さんは北京外国語大学の三年生です。王さんは親友がいます。高校時代の同級生の楊さんです。楊さんは天津大学の三年生です。ある冬の土曜日、二人は久しぶりに会いました。二人は９時に北京駅で待ち合わせました。二人はまず天安門まで地下鉄で行きました。そこで写真を撮りました。天安門からワンフーチンまで歩きました。喫茶店でコーヒーを注文しました。楊さんはコーヒーにミルクも砂糖も入れません。それから、王さんはコートが欲しかったので、デパートへ買いに行きました。いいコートがありましたが、高かったので、買いませんでした。代わりに、セーターを買いました。その後、二人は公園で将来の夢を語り合いました。とても寒かったです。でも、楽しかったです。空港で待っています東京大学大学院への留学決定、おめでとうございます来日は２５日ですね。到着は何時の予定ですか。教えてください。その日は土曜日なので、空港まで迎えに行きます。空港の到着ロビーで待っています。私は日本に帰ってから、ある会社に就職しました。今、中国との貿易の仕事をしています。中国語も使います。毎日残業しています。北京での日々はとても懐かしいです。住居について、決して心配いりません。いくて安いアパートを紹介します。安心してください。では、お元気で、ご家族の皆様にもよろしく。日本人の留学日本の若者にとって、現在、留学や海外旅行は珍しいことではありません。例えば、新婚旅行で国内旅行を選ぶ人はとても少ないと思います。多くのカップルがハワイやヨーロッパは言うまでもなく、世界各地へ行きます。大学生は夏休みに短期留学やホームステイをします。中国各地を個人旅行する学生も大勢います。日本は世界でも最も物価が高い国の一つです。国内旅行の方が、海外旅行より値段が高いという人もいます。また短期旅行や留学の場合、ビザが不要な国もたくさんあります。留学が簡単なのはいいことです。しかし、一生懸命勉強しない人は少なくありません。それは決していいことではありません。貴重の青春時代、１日１日が大切なのは言うまでもありません。インターネットと携帯電話インターネットは、私達の生活に大きな変化をもたらしました。インターネットのお陰で、私達は世界中のことを知ることができます。図書館に行かなくても自宅で何でも調べるとことができます。またインターネットのお陰で通信も便利になりました。手紙の時は何日も掛かりました。しかし、今では、Eメールのおかげで、すぐにメッセージや写真を送ることができます。携帯電話も私達の生活を変えました。以前は公衆電話を探すために走り回りました。今はもう、その必要はありません。どこにいても、家族や友達とおしゃべりすることができます。しかし、インターネットには多くの問題も残っています。IT技術の進歩は、今後の私達の生活をどのように変えるのでしょうか一人っ子のしつけ中国の都市では、少数民族などの家庭を除けば、子供はみんな一人っ子です。趙龍さんの息子さん、趙小龍君もそうです。趙さんは息子について、次のように話しています。皆さんはどう思いますか息子は今９歳で、小学三年生です。勉強はまあまあですけれども、運動は下手です。太っているからでしょうか。息子は休みによくデパートへ行きたがります。そして、新しい服をほしがります。またファスっとフーッとの店でハンバーガーを食べたがります。中華料理の方がいいと思います。私は息子に厳しくて、妻は息子に甘いです。どんどんわがままになっています。以前、家族で上海へ行ったことがあります。あるデパーとへ行った時、息子はやはり５００元もする靴をほしがりました。でも、すでにたくさん持っているので、買いませんでした。すると、息子は大声で泣き出しました。いったい、どうのようにこの子をしつければいいのでしょうか","categories":[{"name":"日本語","slug":"日本語","permalink":"https://blog.lizeyan.me/categories/日本語/"}],"tags":[]},{"title":"用言","slug":"日本語/用言","date":"2020-03-27T09:10:54.116Z","updated":"2020-03-27T09:10:54.116Z","comments":true,"path":"日本語/用言/","link":"","permalink":"https://blog.lizeyan.me/日本語/用言/","excerpt":"","text":"で1. 体言で 动作进行的场所それから食堂で朝ごはんを食べます晩ご飯の後 教室で予習をします日曜日はよく部屋でギターを弾きますその後 １１時１５分まで大学の近くのレストランで アルバイトをします二人は ９時に 北京駅で 待ち合わせました喫茶店で コーヒーを 注文しましたそこで 写真を撮りましたその後 公園で 将来の夢を 語り合いました大学院で MBAをとりたいです日本で生活する北京での日々はとても懐かしですそこの店で待っています2. 体言で 动作的方式方法ときどき ラジオで音楽を聴きます電話で 友達と話をします万年筆で 手紙を書きます二人は まず 天安門まで 地下鉄で いきましたすると、息子は大声で泣き出しました3. 体言で 范围日本で もっとも 人口が おおい 都市です東京では 四月の初めに 桜が咲きます例えば 新婚旅行で 国内旅行を選ぶ人はとても少ない と思います日本は世界でも最も物価が高い国の一つです旅行で 一番いきたいところはどこですかしかし、今ではEメールのおかげで、すぐにメッセージや写真を送ることができます以前、家族で上海へ行ったことがあります4. 体言で 原因山田さんは病気でパーテイーにこなかった私達はインターネットで世界中の情報を得ることができます5. 形容动词，体言的中顿息子は今９歳で、小学三年生ですへ体言へ 动作的方向その後 王さんは コートがほしかったので でパートへ 買いに いきました今日 王さんは 学校へ 勉強に きましたに1. 体言に 比例的基准週に 三回くらい パソコンをします弟は 一日に二時間 本を読みます二人は 久しぶりに 会いました2 体言に 动作的对象高校生に英語を教えます毎週 両親に電話をします先生に 質問をします楊さんは コーヒーに ミルクも 砂糖も 入れません私達の生活に大きの変化をもたらしましたIT技術の進歩は、今後の私達の生活にどのように変えるのでしょうかお互いに 頑張りましょ今晩 一緒に 食事をしましょ私は息子に厳しいですが、妻は息子に甘いです3 （时间）体言に 动作发生的具体时间私は 毎朝 ６時に 起きます姉は いつも ６時に 起きます授業は ８時に始まります二人は ９時に 北京駅で 待ち合わせました大学生は 夏休みに 短期留学やホームステイをします4 （处所）体言に 场所。和で的区别是强调静态的存在？机の上に 何がありますが王さんには 親友がいますアメリカに 留学したいです私は北京に残って アルバイトとするつもりですお盆の前には 北京に戻りますどこにいても、家族や友達とおしゃべりすることができますしかし、インターネットには多くの問題も残っています5. サ变动词词干or动词连用形 に 目的映画を見に いきましょ毎日 家へ ご飯お食べに 帰ります食事に いきます勉強に きましたと1. 体言と 动作行为的共同者友達と 昼ご飯を食べます毎朝 母と 一緒に 散歩をします午後 だれと テニスをしますか昨日 李さんは だれど でパートえ いきましたか友人との一日中国との貿易の仕事をしていますどこにいても、家族や友達とおしゃべりすることができます走ったり、止まったり本物の犬と同じことができます2. 用言终止形と（思う、いう） 表示前面是思考或者说的内容例えば 新婚旅行で 国内旅行を選ぶ人はとても少ない と思いますこれは決していいことではないと思います私は 彼が来る と思います田中さんは お金を待っている と言いました国内旅行の方が、海外旅行より値段が高いと言う人もいます中華料理の方がいいと思います貧乏と言うものは辛いですが中顿，表示转折いいコートがありましたが 高かったので 買いませんでした私は息子に厳しいですが、妻は息子に甘いですけれども中顿，表示转折，同が，口语勉強はまあまあですけれども、運動は下手です勉強はまで1. (时间地点)体言まで 直到その後 １１時１５分まで大学の近くのレストランで アルバイトをします二人は まず 天安門まで 地下鉄で いきました天安門から 王府井まで 歩きました若いころ、遅くまで仕事をすることはよくありますない动词未然形ない山田さんは病気でパーテイーにこなかった私はそのとこを何も知らない忙しくて日記を書くないこともあるから1. (时间地点)体言から 从～开始天安門から 王府井まで 歩きました明日から ６時に 起きます家から 美術館へ 行きます2. 用言终止形から 表示原因。太っているからでしょうかので用言连体形ので 因为その後 王さんは コートがほしかったので でパートへ 買いに いきましたいいコートがありましたが 高かったので 買いませんでした彼は 若いので 元気があります図書館は 静かなので よく そこで 勉強します日曜日なので 休みですその日は土曜日なので 空港まで迎えにいきますちょっとお手洗いに行きたいので 待っていてください図書館でも勉強できるので、学生たちはよく利用していますでも、すでにたくさん持っているので、買いませんたい用言连用形たい 第一人称的愿望。表示疑问时可为二三人称将来 何に なりたいですかアメリカに 留学したいです日本料理を 食べたくないですきの 家へ 帰りたかったです読みたい本が たくさんありますいきたければ 行ってもいいです週末 何をしたいですたがる 动词，第三人称的愿望息子は休みによくデパートへ行きたがりますまた、ファーストフードの店でハンバーガーを食べたがりますほしがる第三人称的“想要”それて新しい服をほしがりますなる1. 体言になる 变成～何になりたいですか先生になりたいです2. 时间体言になる 到了～春になりました８時になりました冬になれば、スキーをする3. 形容词连用形 なる寒くなりました見れば、買いたくなります4. 形容动词になる静かになりました便利になりました私は もっと 中国語が上手に なりたいですまた、インターネットのおかげで通信も便利になりました動物ロボットも当たり前になるでしょうどんどんわがままになっていますも在数量词之后表示多手紙の時は何日も掛かりましたあるデパートに行った時、息子はやはり５００元もする靴をほしがりました也携帯電話も私達の生活を変えましたて动词音便形て 动作的连续并列あそこに行って、ちょっと休みましょか私は北京に残って アルバイトとするつもりです形容词的中顿忙しくて 日記を書かないことがあるの表示领属关系，或者状况，同位，属性等。。。。。形式体言留学が簡単なのはいいことです貴重の青春時代 一日一日が大切なのは言うまでもありませんIT技術の進歩は、今後の私達の生活にどのように変えるのでしょうかても用言连用形（动词音便形）ても 逆态接续，“即使”図書館に行かなくても自宅で何でも調べることができますどこにいても、家族や友達とおしゃべりすることができますこれはどんなに便利でも、利用したくないです雨が降っても、行きますでも1.（体言、形容动词词干）でも 连～都；即使～それは子供でもできる問題です明日の運動会は、雨天でも決行します2. 接在疑问词后，表示全面肯定スーパーでは何でも売っています3. 副词 但是でも、すでにたくさん持っているので、買いませんこと形式体言インターネットのお陰で、私達は世界中のことお知ることができますどこにいても、家族や友達とおしゃべりすることができますため（用言连体形，体言の）ため 目的以前は、公衆電話を探すために走り回りました人は食べるために生きるのではなく、生きるために食べるのです健康のために、早寝早起きをしましょう（用言连体形，体言の）ため 原因つもり用言连体形つもり 表示打算私は北京に残って アルバイトとするつもりです万里の長城を案内するつもりですより1. 〜の方が体言より 比起～，～更国内旅行の方が、海外旅行値段が高いと言う人もいますほど～ほど～はありません 表示在后面没有可比前面的その中でも 沖縄の海ほど 美しい海はありませんてから动词音便形てから ～之后 ～～私は日本に帰ってから ある会社に就職しましたについて体言について 关于～趙さんは 息子さんについて 次のように話ています住居については 決して 心配いりませんにとって体言にとって 对于～日本の若者にとって 留学や海外旅行が珍しいことではありません言うまでもない体言は言うまでもない ～自不必说多くのカプルが ハワイやヨーロッパは言うまでもなく、世界各地へ行きます貴重の青春時代 一日一日が大切なのは言うまでもありませんのおかげで体言のお陰で thanking toインターネットのお陰で、私達は世界中のことを知ることができますまた、インターネットのお陰で通信も便利になりましたしかし、今ではEメールのおかげで、すぐにメッセージや写真を送ることができますたり用言连用形（动词音便形）たり 又～又～走ったり、止まったり本物の犬と同じことができます","categories":[{"name":"日本語","slug":"日本語","permalink":"https://blog.lizeyan.me/categories/日本語/"}],"tags":[]},{"title":"Statistical Test","slug":"Statistics/test","date":"2020-03-27T09:10:54.112Z","updated":"2020-03-27T09:10:54.112Z","comments":true,"path":"Statistics/test/","link":"","permalink":"https://blog.lizeyan.me/Statistics/test/","excerpt":"","text":"[TOC]Two-Sample Kolmogorov–Smirnov TestTwo-sample Kolmogorov–Smirnov (KS) test may be used to test whether two underlying one-dimentional probability distributions differ.In this case, the KS statistic is \\[ D_{m,n}=\\sup{x} |F_{1,n}(x)-F_{2,m}(x)|, \\] where \\(F_{1,n}\\) and \\(F_{2,m}\\) are the empirical distribution functions of the first and second sample respectively, and \\(n\\) and \\(m\\) are the size of them.Empirical distribution function is defined as follows: \\[ F_{n}(x)=\\frac{1}{n}\\sum_{i=1}^{n}I_{(-\\infty, x]}(X_i) \\] Null hypothesis is a statement of 'no effect' or 'no difference'.For large samples, the null hypothesis is rejected at level \\(\\alpha\\) if \\[ D_{n,m}&gt;c(\\alpha)\\sqrt{\\frac{n+m}{nm}} \\]\\(\\alpha\\)0.100.050.0250.010.0050.001\\(c(\\alpha)\\)1.0731.2241.3581.5171.6281.858In general, \\[ c(\\alpha)=\\sqrt{-\\frac{1}{2}\\alpha} \\]T-TestChi-Squared TestSuppose \\(n\\) observations are classified into \\(k\\) mutually exclusive classes with respectiive observed numbers \\(x_i\\), and a null hypothesis gives the probablity \\(p_i\\) the an observation falls into the \\(i\\)-th class.Then we have the expeccted numbers \\(m_i=np_i\\)As \\(n\\to \\infty\\), the following quantity follows \\(\\chi^2\\) distribution with \\(k-1\\) freedom: \\[ X^2=\\sum_{i=1}^{k}\\frac{(x_i-m_i)^2}{m_i} \\] The CDF of \\(\\chi^2\\) distribution is as follows:{;({},,{});}CDF curveThe following table gives the \\(p\\)-values matching to \\(\\chi^2\\) for the first 10 degress of freedom.image-20190720104022004","categories":[{"name":"Statistics","slug":"Statistics","permalink":"https://blog.lizeyan.me/categories/Statistics/"}],"tags":[]},{"title":"Reinforcement Learning","slug":"StatisticalMachineLearning/reinforcement_learning","date":"2020-03-27T09:10:54.108Z","updated":"2020-03-27T09:10:54.108Z","comments":true,"path":"StatisticalMachineLearning/reinforcement_learning/","link":"","permalink":"https://blog.lizeyan.me/StatisticalMachineLearning/reinforcement_learning/","excerpt":"","text":"[TOC]IntroductionAgent:At each step \\(t\\), the agentReceives state \\(s_t\\)Receives scalar reward \\(r_t\\)Executes action \\(a_t\\)Agent's goal is learn a policy to maximize long-term total reward:\\(\\sum_{t=1}^{T}r_t\\) or \\(\\sum_{t=1}^{\\infty}\\gamma^tr_t\\)EnvironmentReceives action \\(a_t\\)Emits state \\(s_t\\)Emits scalar reward \\(r_t\\)PolicyAgent's behavior \\[ a=\\pi(s) \\] or \\[ \\pi(a|s)=\\mathbb{P}[A_t=a|S_t=s] \\]Value Functionthe prediction of future reward given a state and an actionQ-value function gives expected total reward \\[ Q^{\\pi}(s, a)=\\mathbb{E}[r_{t+1}+\\gamma r_{t+2}+\\gamma^2r_{t+3}+...|s,a] \\] It can be decompose into a Bellman equation \\[ Q^{\\pi}(s, a)=\\mathbb{E}_{s&#39;,a&#39;}[r+\\gamma Q^\\pi(s&#39;,a&#39;)|s,a] \\]ModelA model predicts what the environment will do next \\[ \\mathcal{P}_{ss&#39;}^a=\\mathbb{P}[S_{t+1}=s&#39;|S_t=s,A_t=a]\\\\ \\mathcal{R}_s^a=\\mathbb{E}[R_{t+1}|S_t=s,A_t=a] \\]Markov Decision ProcessHistory is the sequence of observations ,actions, rewards \\[ H_t=O_1,R_1,A_1,...,A_{t-1},O_t,R_t \\] Formmaly, state is a function of the history \\[ S_t=f(H_t) \\] A state \\(S_t\\) is Markov iff \\[ \\mathbb{P}[S_{t+1}|S_t]=\\mathbb{P}[S_{t+1}|S_1,...,S_t] \\] The state is a sufficient statictic of the future. Once you get the state, you can throw the history away.A Markov Decision Process is a tuple \\(&lt;\\mathcal S,\\mathcal A,\\mathcal P,\\mathcal R,\\gamma&gt;\\)\\(\\mathcal S\\) is a finite set of states.\\(\\mathcal A\\) is a finite set of actions\\(\\mathcal P\\) is a state transition probability matrix\\(\\mathcal R\\) is a reward function\\(\\gamma\\) is a discount factorHow to solve the optimal policy in MDP?Value-Based RLPolicy-Based RLMolde-Based RLState value function \\(V^{\\pi}(s)=E[\\sum_{t=1}^{T}r_t|s]\\)State-action value function \\(Q^{\\pi}(s,a)=E[\\sum_{t=1}^{T}r_t|s,a]=\\sum_{s&#39;}P(s&#39;|s,a)(R(s,a,s&#39;)+V^{\\pi}(s&#39;))\\) \\[ V^{\\pi}(s)=\\sum_a\\pi(a|s)Q(s,a) \\]Value Based MethodsPolicy SearchModel-Based \u0010MethodDeep Reinforcement Learning","categories":[{"name":"StatisticalMachineLearning","slug":"StatisticalMachineLearning","permalink":"https://blog.lizeyan.me/categories/StatisticalMachineLearning/"}],"tags":[]},{"title":"SVM","slug":"StatisticalMachineLearning/svm","date":"2020-03-27T09:10:54.108Z","updated":"2020-03-27T09:10:54.108Z","comments":true,"path":"StatisticalMachineLearning/svm/","link":"","permalink":"https://blog.lizeyan.me/StatisticalMachineLearning/svm/","excerpt":"SVM","text":"SVMSVM: Max Margin and Dual ProblemThe basic idea of SVM is max margin: maximize the closest distance of each class to hy classification hyperplane.Let the trainning set \\[ \\{\\boldsymbol{x}_i, y_i\\}_{i=1}^{N}, \\boldsymbol x_i \\in \\mathbb{R}^d, y_i \\in \\{-1, 1\\} \\] be separated by a hyperplane with the margin \\(\\rho\\).Then \\[ \\forall i = 1,2,...,N, y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i+b) \\ge \\frac{\\rho}{2} \\]where \\(\\mathbf{w}​\\) is the unit normal vector of the hyperplane.Then we rescale the hyperplane with \\(\\frac{\\rho}{2}​\\) \\[ \\forall i = 1,2,...,N, y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i+b) \\ge 1 \\] For support vectors \\(\\boldsymbol{x}_s\\)the above inequality is equality.So now the margin is \\[ \\rho = 2r=2 \\frac{|\\boldsymbol{w}^\\top\\boldsymbol x_s+b|}{||\\boldsymbol{w}||}=\\frac{2}{||\\boldsymbol{w}||} \\]Now we get the primal problem: \\[ \\min \\frac{1}{2}||\\boldsymbol{w}||^2 \\\\ s.t.\\&gt;\\&gt;\\&gt;\\&gt; y_i(\\boldsymbol{w}^\\top\\boldsymbol{x}_i +b)\\ge1, \\forall i = 1,2,...,N \\]The predict function is \\[ \\hat y = f(\\boldsymbol x)=\\text{sign}(\\boldsymbol{w}^\\top \\boldsymbol x + b) \\]Lagrangian function: \\[ L(\\boldsymbol{w}, b, \\boldsymbol\\alpha) = \\frac{1}{2}||\\boldsymbol{w}||^2 - \\sum_{i=1}^{N}\\alpha_i (y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i+b) - 1), \\boldsymbol \\alpha \\ge 0 \\] The primal problem is \\(\\min_\\boldsymbol{w, b} \\max_{\\boldsymbol \\alpha \\ge 0} L(\\boldsymbol{w}, b, \\boldsymbol \\alpha)\\)Then the dual problem is \\(\\max_{\\boldsymbol \\alpha \\ge 0} \\min_{\\boldsymbol{w},b}L(\\boldsymbol{w},b,\\boldsymbol \\alpha)​\\)To minimize with parameter \\(\\boldsymbol{w}\\) and \\(b\\), their deriative should be zeros: \\[ \\frac{\\partial L}{\\partial \\boldsymbol{w}}=\\boldsymbol{w}-\\sum_{i=1}^{N}\\alpha_i y_i\\boldsymbol x_i \\\\ \\frac{\\partial L}{\\partial b} = -\\sum_{i=1}^{N}\\alpha_iy_i \\] Therefore: \\[ \\boldsymbol{w}^*=\\sum_{i=1}^{N}\\alpha_iy_i\\boldsymbol x_i\\\\ \\sum_{i=1}^{N}\\alpha_iy_i=0 \\] Then substitute \\(\\boldsymbol{w}\\): \\[ L(\\boldsymbol \\alpha, b)=\\frac{1}{2}||\\sum_{i=1}^{N}\\alpha_iy_i\\boldsymbol x_i||^2-\\sum_{i=1}^{N}[\\alpha_iy_i\\sum_{j=1}^N\\alpha_jy_j\\boldsymbol x_j^\\top \\boldsymbol x_i+\\alpha_iy_ib] \\\\ =\\boldsymbol \\alpha^\\top \\boldsymbol 1 - \\frac{1}{2}\\boldsymbol \\alpha^\\top\\mathbf{Y}\\mathbf{G}\\mathbf{Y}\\boldsymbol \\alpha - b \\sum_{i=1}^{N}\\alpha_iy_i \\\\ =\\boldsymbol \\alpha^\\top \\boldsymbol 1 - \\frac{1}{2}\\boldsymbol \\alpha^\\top\\mathbf{Y}\\mathbf{G}\\mathbf{Y}\\boldsymbol \\alpha \\]Now we get the dual problem: \\[ \\max \\boldsymbol \\alpha^\\top \\boldsymbol 1 - \\frac{1}{2}\\boldsymbol \\alpha^\\top\\mathbf{Y}\\mathbf{G}\\mathbf{Y}\\boldsymbol \\alpha \\\\ s.t.\\&gt;\\&gt;\\&gt;\\&gt;\\boldsymbol \\alpha\\ge0 \\]In order to place the hyperplane in the middle of two classes: \\[ b=-\\frac{\\max_{i:y_i=-1}\\boldsymbol{w}^\\top\\boldsymbol x_i + \\min_{i:y_i=+1}\\boldsymbol{w}^\\top\\boldsymbol x_i}{2} \\] Accoding to the complement slackness condition: \\[ \\alpha_i(y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i+b) - 1)=0 \\] So only support vectors matter.Soft SVMWhat if the problem is not linear-seperatable?The hard SVM primal problem can be rewritten as follows: \\[ \\min \\frac{1}{2}||\\boldsymbol{w}||^2+\\sum_{i=1}^{N}l_{0-\\infty}(y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i + b) - 1) \\\\ l_{0-\\infty}(x)=\\begin{cases}0&amp;x\\ge0\\\\\\infty&amp;x&lt;0\\end{cases} \\]Try to tolerate: \\[ \\min \\frac{1}{2}||\\boldsymbol{w}||^2+\\sum_{i=1}^{N}l_{0-1}(y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i + b) - 1) \\\\ l_{0-1}(x)=\\begin{cases}0&amp;x\\ge0\\\\1&amp;x&lt;0\\end{cases} \\]But this problem is not convex.image-20190308220605185Hinge loss upper bounds the 0-1 loss. \\[ l_{lin}(x)=\\max(0, x+1) \\]Take hinge loss as an example to solve soft SVM.Now the problem is \\[ \\min \\frac{1}{2}||\\boldsymbol{w}||^2+\\sum_{i=1}^{N}l_{lin}(y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i + b)) \\\\ l_{lin}(x)=\\max(0, 1-x) \\]Rewrite this problem, and rescale the loss by \\(C\\): \\[ \\min \\frac{1}{2}||\\boldsymbol{w}||^2+C\\sum_{i=1}^{N}\\xi_i\\\\ s.t. \\&gt;\\&gt;\\&gt;\\&gt; y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i+b) \\ge 1-\\xi_i,\\forall i=1,2,...,N\\\\ \\boldsymbol \\xi \\ge \\boldsymbol 0 \\]The Lagrangian function is: \\[ L(\\boldsymbol{w}, \\boldsymbol \\xi, \\boldsymbol \\alpha, \\boldsymbol \\beta)= \\frac{1}{2}||\\boldsymbol{w}||^2+C\\sum_{i=1}^{N}\\xi_i - \\sum_{i=1}^{N}\\alpha_i(y_i(\\boldsymbol{w}^\\top\\boldsymbol x_i+b) - 1 + \\xi_i) - \\sum_{i=1}^{N}\\beta_i\\xi_i \\] Minimize \\(\\mathbf{w}\\) and \\(\\boldsymbol \\xi\\): \\[ \\frac{\\partial L}{\\partial \\boldsymbol{w}}=\\boldsymbol{w}-\\sum_{i=1}^{N}\\alpha_iy_i\\boldsymbol x_i \\\\ \\frac{\\partial L}{\\partial \\boldsymbol \\xi}=C \\boldsymbol 1 - \\boldsymbol \\alpha - \\boldsymbol \\beta \\] Therefore \\[ \\boldsymbol \\beta = C \\boldsymbol 1 - \\boldsymbol \\alpha \\ge \\boldsymbol 0\\\\ \\boldsymbol w = \\sum_{i=1}^{N}\\alpha_iy_i\\boldsymbol x_i \\] Then we get the dual problem: \\[ \\max \\boldsymbol \\alpha^\\top \\boldsymbol 1 - \\frac{1}{2}\\boldsymbol \\alpha^\\top\\mathbf{Y}\\mathbf{G}\\mathbf{Y}\\boldsymbol \\alpha \\\\ s.t.\\&gt;\\&gt;\\&gt;\\&gt;C\\boldsymbol 1\\ge\\boldsymbol\\alpha\\ge\\boldsymbol0 \\]Kernel\\[ \\mathbf{G}=(\\boldsymbol x_i^\\top \\boldsymbol x_j)_{N\\times N} \\]","categories":[{"name":"StatisticalMachineLearning","slug":"StatisticalMachineLearning","permalink":"https://blog.lizeyan.me/categories/StatisticalMachineLearning/"}],"tags":[]},{"title":"NB and LR","slug":"StatisticalMachineLearning/nb_and_lr","date":"2020-03-27T09:10:54.096Z","updated":"2020-03-27T09:10:54.096Z","comments":true,"path":"StatisticalMachineLearning/nb_and_lr/","link":"","permalink":"https://blog.lizeyan.me/StatisticalMachineLearning/nb_and_lr/","excerpt":"Naive Bayesian and Logistic Regression","text":"Naive Bayesian and Logistic RegressionNBMLESettings:\\[ p(y|\\pi)=\\begin{cases}\\pi &amp; y=1 \\\\ 1-\\pi &amp; y=0\\end{cases} \\\\ p(x|y, q)=\\begin{cases}q_y &amp; x=1 \\\\ 1-q_y &amp; x=0\\end{cases} \\]Log likelihood: \\[ \\mathcal{L} = \\log \\prod_{i=1}^{N}p(x_i, y_i)\\\\ =\\sum_{i=1}^{N}\\log p(x_i|y_i)+\\log p(y_i) \\\\ =\\sum_{i=1}^{N}x_i\\log q_{y_i} + (1-x_i)\\log (1 - q_{y_i}) + y_i\\log \\pi + (1-y_i)\\log (1 - \\pi) \\]MLE\\[ \\frac{\\partial \\mathcal{L}}{\\partial \\pi}=\\sum_{i=1}^{N}\\frac{1}{\\pi}1_{y_i=1}-\\frac{1}{1-\\pi}1_{y_i=0}\\\\ =\\frac{1}{1-\\pi}\\sum_{i=1}^{N}\\frac{1}{\\pi}1_{y_i=1}-1 \\]Therefore \\(\\pi=\\frac{N_1}{N}\\) \\[ \\frac{\\partial \\mathcal{L}}{\\partial q_y}=\\sum_{i=1}^{N}1_{y_i=y}(\\frac{1}{q_y}1_{x_i=1}-\\frac{1}{1-q_y}1_{x_i=0})\\\\ =\\frac{1}{1-q_y}\\sum_{i=1}^{N}1_{y_i=y}(\\frac{1}{q_y}1_{x_i=1}-1) \\] Therefore \\(q_y=\\frac{N_{y, 1}}{N_y}\\)Laplace smoothing\\[ \\pi=\\frac{N_1+\\alpha}{N+2\\alpha} \\]MAPConjugate_priorUse Beta distribution as the prior \\[ p(q_y)=\\frac{\\Gamma(\\alpha_1+\\alpha_2)}{\\Gamma(\\alpha_1)\\Gamma(\\alpha_2)}q_y^{\\alpha_1-1}(1-q_y)^{\\alpha_2-1} \\] Now the log likelihood is: \\[ \\mathcal{L} = \\log p(q_y) + \\log \\prod_{i=1}^{N}p(x_i, y_i) \\\\ =\\sum_{i=1}^{N}x_i\\log q_{y_i} + (1-x_i)\\log (1 - q_{y_i}) + y_i\\log \\pi + (1-y_i)\\log (1 - \\pi) \\\\ + (\\alpha_1-1)\\log q_y+ (\\alpha_2-1)\\log (1-q_y) \\]\\[ \\frac{\\partial \\mathcal{L}}{\\partial q_y}=\\sum_{i=1}^{N}1_{y_i=y}(\\frac{1}{q_y}1_{x_i=1}-\\frac{1}{1-q_y}1_{x_i=0})\\\\ + (\\alpha_1-1)\\frac{1}{q_y} - (\\alpha_2-1)\\frac{1}{1-q_y}\\\\ =\\frac{1}{1-q_y}\\sum_{i=1}^{N}1_{y_i=y}(\\frac{1}{q_y}1_{x_i=1}-1)+ (\\alpha_1-1)\\frac{1}{q_y} - (\\alpha_2-1)\\frac{1}{1-q_y} \\\\ =\\frac{1}{1-q_y}(\\frac{1}{q_y}N_{y,1}-N_y-\\alpha_2+1)+(\\alpha_1-1)\\frac{1}{q_y} \\\\ \\therefore q_y=\\frac{N_{y,1}+\\alpha_1-1}{N+\\alpha_1+\\alpha_2-2} \\]image-20190418201126654Beyesian Regression$$ \\newcommand{\\vv}[1]{\\boldsymbol{#1}} y=f(\\vv{x})+\\epsilon, \\epsilon \\sim \\mathcal{N}(0, \\sigma^2) $$ $$ p(\\vv{y}|\\mathbf{X}, \\vv{w})=\\prod_{i=1}^{N}p(y_i|\\vv{x_i}, \\vv{w})=N(X^\\top\\vv{w}, \\sigma^2\\mathbf{I}) $$Prior is Gaussian \\[ p(\\vv{w})=\\mathcal{N}(\\mathbf{0}, \\mathbf{\\Sigma}) \\] Since the posterior is Gaussian, we only need to determine the mean and covariance. \\[ \\text{let } p(\\vv{w}|\\mathbf{X},\\vv{y})=\\mathcal{N}(\\vv\\mu, \\mathbf{\\Sigma_1})\\\\ -\\frac{1}{2}\\sigma^{-2}(\\vv{y}^\\top\\vv{y}-2\\vv{y}^\\top\\mathbf{X}^\\top\\vv{w}+\\vv{w}^\\top\\mathbf{X}\\mathbf{X}^\\top\\vv{w}+\\vv{w}^\\top\\mathbf{\\Sigma}^{-1}\\vv{w}) \\\\ \\therefore \\mathbf{\\Sigma_1}=\\mathbf{A}^{-1}, \\mathbf{A}=\\sigma^{-2}\\mathbf{X}\\mathbf{X}^\\top+\\mathbf{\\Sigma}^{-1}\\\\ \\therefore \\vv{\\mu}^\\top \\mathbf{A}=\\sigma^{-2}\\vv{y}^\\top\\mathbf{X}^\\top\\\\ \\therefore \\vv{\\mu}=\\sigma^{-2} \\mathbf{A}^{-1}\\mathbf{X}\\vv{y} \\] ### Generalized NBapplied to continious features \\[ Y\\sim\\text{Bernoulli}(\\pi)\\\\ P(X|Y)=\\mathcal{N}(\\mu_{Y}, \\sigma_{Y}^2) \\] The MLE estimated mean and variance is the sample mean variance on those samples with corresponding \\(Y\\).image-20190418212303876Decision Boundary of NBNB's decisiion boundary depends on its distribution assumptions.for GNB with equal variance: \\[ \\log \\frac{\\prod_{i=1}^{d}P(X_i|Y_i=0)P(Y_i=0)}{\\prod_{i=1}^{d}P(X_i|Y_i=1)P(Y_i=1)}=0 \\\\ \\log \\frac{1-\\pi}{\\pi}+\\sum_i \\frac{\\mu_{i1}^2-\\mu_{i0}^2}{\\sigma_i^2}+\\sum_i\\frac{\\mu_{i0}-\\mu_{i1}}{\\sigma_i^2}x_i = 0 \\] therefore the decision boundary is linearBut if the variances are not equal, it is not linear.Linear RegressionFrom NB to LR\\[ P(y=1|\\vv{x})=\\frac{p(y=1, \\vv{x})}{p(y=1, \\vv{x}) + p(y=0, \\vv{x})} \\\\ =\\frac{1}{1+\\frac{p(y=0, \\vv{x})}{p(y=1, \\vv{x})}} \\\\ =\\frac{1}{1+\\exp(-\\vv{w}^\\top\\vv{x}-b)} \\]sigmoid function\\[ \\sigma(x)=\\frac{1}{1+\\exp(-x)}\\\\ \\frac{d\\sigma}{dx}=\\sigma(x)(1-\\sigma(x)) \\\\ 1-\\sigma(x)=\\sigma(-x) \\]Multiclass LRimage-20190418213726821decision boundary is not linear, it is piecewise linearMaximum Conditional Likelihood EstimateMLE is \\(\\max P(X, Y)\\), but we don't have it in LR.In MCLE, we do \\(\\max P(Y|X)\\)It is a Convex Problem\\[ \\mathcal{L}(\\vv{w})=\\sum_{i=1}^{N}\\log p(y_i|\\vv{x}_i, \\vv{w})\\\\ =\\sum_{i=1}^{N}y_i\\vv{w}^\\top\\vv{x}_i-\\log(1+\\exp(\\vv{w}^\\top\\vv{x}_i)) \\]Gradient Descent\\[ \\frac{\\partial \\mathcal{L}}{\\partial \\vv{w}}=\\sum_{i=1}^{N}\\vv{x}_i(y_i-u_i)\\\\ u_i=p(y_i=1|\\vv{x}_i, \\vv{w})=\\sigma(-\\vv{w}^\\top\\vv{x}) \\]\\[ \\vv{w}_{t+1}\\leftarrow \\vv{w}_t + \\frac{\\partial \\mathcal{L}}{\\partial \\vv{w}} \\]Newton Method\\[ \\vv{w}_{t+1}\\leftarrow \\vv{w}_t - \\mathbf{H}^{-1}\\frac{\\partial \\mathcal{L}}{\\partial \\vv{w}}\\\\ \\mathbf{H} = \\frac{\\partial^2 \\mathcal{L}}{\\partial\\vv{w}\\partial\\vv{w}} \\]IRLS\\[ \\nabla_\\vv{w}\\mathcal{L}=\\sum_{i=1}^{N}\\vv{x}_i(y_i-u_i)=\\mathbf{X}(\\vv{y}-\\vv{u})\\\\ \\mathbf{H}=\\nabla^2_\\vv{w}\\mathcal{L}=\\sum_{i=1}^{N}-\\vv{x}_iu_i(1-u_i)\\vv{x}_i^\\top=-\\mathbf{X}\\mathbf{R}\\mathbf{X}^\\top \\\\ \\mathbf{R}_{ii}=u_i(1-u_i) \\]For least square of linear regression, we have \\[ \\vv{w}=(\\mathbf{X}\\mathbf{X}^\\top)^{-1}\\mathbf{X}\\vv{y} \\] IRLS: \\[ \\vv{w}_{t+1}\\leftarrow\\vv{w}_t - \\mathbf{H}^{-1}\\nabla_\\vv{w}\\mathcal{L}\\\\ =\\vv{w}_t-(\\mathbf{X}\\mathbf{R}\\mathbf{X}^\\top)^{-1}\\mathbf{X}(\\vv{u}-\\vv{y})\\\\ =(\\mathbf{X}\\mathbf{R}\\mathbf{X}^\\top)^{-1}(\\mathbf{X}\\mathbf{R}\\mathbf{X}^\\top\\vv{w}_t - \\mathbf{X}(\\vv{u}-\\vv{y}))\\\\ =(\\mathbf{X}\\mathbf{R}\\mathbf{X}^\\top)^{-1}\\mathbf{X}\\mathbf{R}(\\mathbf{X}^\\top\\vv{w}_t - \\mathbf{R}^{-1}(\\vv{u}-\\vv{y})) \\]Generative v.s. DiscrimitiveGenrative model has assumptions on \\(P(X|Y)\\), discrimitive models has assumptions on \\(P(Y|X)\\).image-20190419102050758image-20190419102100816Exponential FamilyGeneral Form\\[ p(\\vv{x}|\\vv{\\eta})=h(\\vv{x})g(\\vv{\\eta})\\exp(\\vv\\eta^\\top\\vv u(\\vv{x}))\\\\ =h(\\vv{x})\\exp(\\vv\\eta^\\top\\vv{u}(\\vv{x})-A(\\vv\\eta)) \\]\\(g(\\vv\\eta)\\) is the normalization coefficient.More refefence hereimage-20190419104811404image-20190419104825706image-20190419104845782image-20190419104916055Bernoulli\\[ p(x|\\mu)=\\mu^{x}(1-\\mu)^{1-x} \\\\ =\\exp(x\\log\\mu+(1-x)\\log(1-\\mu)) \\\\ =(1-\\mu)\\exp(\\log\\frac{\\mu}{1-\\mu}x)\\\\ = \\sigma(-\\eta)\\exp(\\eta x) \\]\\[ \\eta=\\log\\frac{\\mu}{1-\\mu}\\\\ h(x)=1\\\\ g(\\eta)=\\sigma(-\\eta)\\\\ u(x)=x \\]Multinominal\\[ p(\\vv{x}|\\vv{\\mu})=\\prod_{k=1}^{M}\\mu_k^{x_k}\\\\ =\\exp(\\sum x_k\\log \\mu_k) \\\\ =\\exp(\\sum_{i=1}^{M-1}x_k\\log \\mu_k+(1-\\sum_{i=1}^{M-1}x_k)\\log(1-\\sum_{k=1}^{M-1}\\mu_k))\\\\ =(1-\\sum_{i=1}^{M-1}\\mu_k)\\exp(\\sum_{k=1}^{M-1}x_k\\log(\\frac{\\mu_k}{1-\\sum_{k=1}^{M-1}\\mu_k}))\\\\ =\\frac{(1-\\sum_{k=1}^{M-1}\\mu_k)}{\\mu_M}\\exp(\\sum_{k=1}^{M}x_k\\log\\mu_k) \\\\ =\\exp(\\sum_{k=1}^{M}x_k\\log\\mu_k) \\]\\[ \\vv\\eta=(\\log \\mu_1, \\log \\mu_2, ..., \\log\\mu_M)^\\top \\\\ \\vv u(\\vv{x})=\\vv{x}\\\\ h(\\vv{x})=1\\\\ g(\\eta)=1 \\]Multivariate Gaussian\\[ p(\\vv{x}|\\vv\\mu, \\mathbf{\\Sigma})=\\frac{1}{(2\\pi)^\\frac{d}{2}|\\Sigma|^\\frac{1}{2}}\\exp(-\\frac{1}{2}(\\vv x - \\vv\\mu)^\\top\\Sigma^{-1}(\\vv x - \\vv\\mu))\\\\ =\\frac{1}{(2\\pi)^\\frac{d}{2}|\\Sigma|^\\frac{1}{2}}\\exp(-\\frac{1}{2}\\text{tr}(\\Sigma^{-1}\\vv{x}\\vv{x}^\\top)+\\vv\\mu^\\top\\Sigma^{-1}\\vv{x}-\\frac{1}{2}\\vv\\mu^\\top\\Sigma^{-1}\\vv\\mu)\\\\ \\]then \\[ \\vv{\\eta}=\\begin{bmatrix}\\Sigma^{-1}\\vv{\\mu}, -\\frac{1}{2}\\text{vec}(\\Sigma^{-1}) \\end{bmatrix} \\\\ =[\\vv\\eta_1, \\text{vec}(\\vv{\\eta}_2)]\\\\ \\vv{u}(\\vv{x})=\\begin{bmatrix}\\vv{x}, \\text{vec}(\\vv{x}\\vv{x}^\\top)\\end{bmatrix} \\]\\[ g(\\vv{\\eta})=|\\Sigma|^{-\\frac{1}{2}}\\exp(-\\frac{1}{2}\\vv\\mu^\\top\\Sigma^{-1}\\vv{\\mu})\\\\ =|-2\\vv{\\eta}_2|^{\\frac{1}{2}}\\exp(-\\frac{1}{2}((-2\\vv\\eta_2)^{-1}\\vv\\eta_1)^\\top\\vv\\eta_1)\\\\ =|-2\\vv{\\eta}_2|^{\\frac{1}{2}}\\exp(+\\frac{1}{4}\\vv\\eta_1^\\top\\vv\\eta_2^{-1}\\vv\\eta_1) \\]Why Exponential FamilyMomentimage-20190419110333901\\[ \\because \\int_xp(x)=1\\\\ \\therefore\\nabla_\\eta\\int_xh(x)\\exp(\\eta^\\top u(x)-A(\\eta))dx=0\\\\ \\therefore\\int_x h(x)\\exp(\\eta^\\top u(x)-A(\\eta))(u(x)-\\nabla_\\eta A(\\eta))dx=0\\\\ \\therefore \\nabla_\\eta A(\\eta)=\\mathbb{E}[u(x)]\\\\ \\because \\nabla_\\eta^2\\int_xh(x)\\exp(\\eta^\\top u(x)-A(\\eta))dx=0\\\\ \\therefore \\int_x h(x)\\exp(\\eta^\\top u(x)-A(\\eta))u^2(x)-h(x)\\exp(\\eta^\\top u(x)-A(\\eta))\\nabla_n A(\\eta) u(x) dx - \\nabla_\\eta^2 A(\\eta)=0\\\\ \\therefore \\nabla_\\eta^2 A(\\eta)=\\mathbb{E}[u^2(x)]-(\\mathbb{E}[u(x)])^2=\\text{Var}[u(x)] \\]MLE for Exponential Falimy with i.i.d. samples\\[ P(D|\\vv\\eta)=\\prod_{i=1}^{N}P(\\vv{x}|\\vv\\eta)\\\\ =(\\prod_{i=1}^{N}h(\\vv{x}_i))\\exp(\\vv\\eta^\\top\\sum_{i=1}^{N}\\vv{u}(\\vv{x}_i)-NA(\\vv\\eta)) \\]It is still a exponential family distribution \\[ \\nabla_{\\vv\\eta}\\log P=\\sum_{i=1}^{N}\\vv{u}(\\vv{x}_i)-N\\nabla_{\\eta}A(\\vv\\eta)\\\\ \\therefore \\vv{\\mu}=\\frac{1}{N}\\sum_{i=1}^{N}\\vv u(\\vv{x}_i) \\] Generailized Linear Models (GLIM) \\[ \\mathbb{E}[y]=u=f(\\vv\\theta^\\top\\vv{x}) \\]\\[ p(y|\\vv{x})=h(\\vv u)\\exp(\\vv\\eta^\\top \\vv u - A(\\vv\\eta)), \\vv u = f(\\vv\\theta^\\top\\vv{x}) \\]When \\(p(y|\\vv{x})\\) is a bernoulli distribution, \\(\\vv{u}=\\sigma(-\\vv{w}^\\top\\vv{x})\\), it is basic linear regression.a \\[ \\mathcal{L}=\\sum_{n}\\log h(\\vv u_n)+\\sum_n({\\vv\\eta_n^\\top\\vv{u}_n-A(\\vv\\eta_n)})\\\\ \\nabla_\\vv\\theta\\mathcal{L}=\\sum_{n}(\\vv{u}_n\\nabla_{\\vv\\theta}\\vv\\eta_n-\\vv\\mu_n\\nabla_{\\vv\\theta}\\vv\\eta_n) \\]","categories":[{"name":"StatisticalMachineLearning","slug":"StatisticalMachineLearning","permalink":"https://blog.lizeyan.me/categories/StatisticalMachineLearning/"}],"tags":[]},{"title":"Dimension Reduction","slug":"StatisticalMachineLearning/dimension_reduction","date":"2020-03-27T09:10:54.092Z","updated":"2020-03-27T09:10:54.092Z","comments":true,"path":"StatisticalMachineLearning/dimension_reduction/","link":"","permalink":"https://blog.lizeyan.me/StatisticalMachineLearning/dimension_reduction/","excerpt":"","text":"PCAAlgorithm$$ preamble \\newcommand{\\vv}[1]{\\boldsymbol{#1}} $$Given data matrix \\(\\mathbf{X}\\), get the \\(d\\)-largest eigenvalues \\(\\lambda_1, ..., \\lambda_d\\) and correbounding egivenvectors \\(\\vv{u}_1, \\vv{u}_2, ..., \\vv{u}_d\\)let \\(\\mathbf{U}=\\begin{bmatrix}\\vv u_1, \\vv u_2,..., \\vv u_d\\end{bmatrix}\\)Encode: \\(\\mathbf{U}^\\top \\mathbf X\\)Decode: $ Z$​Maximum Variance Formulation1-d caseThe projection direction \\(\\vv{u}\\) satisfies \\(||\\vv{u}||=1\\) \\[ y=\\vv{u}^\\top\\vv{x}\\\\ \\bar{\\vv{y}}=\\vv{u}^\\top\\bar{\\vv{x}}\\\\ var(\\vv{y})=\\frac{1}{N}\\sum_{i=1}^{N}(\\vv u^\\top\\vv{x}_n-\\vv{u}^\\top\\bar{\\vv{x}})^2\\\\ =\\vv{u}^\\top \\mathbf{S} \\vv{u}, \\mathbf{S}=\\frac{1}{N}(\\vv{x}_n-\\bar{\\vv{x}})(\\vv{x}_n-\\bar{\\vv{x}})^\\top \\]\\[ \\hat{\\vv{u}}=\\text{argmax}_\\vv{u}\\vv{u}^\\top \\mathbf{S} \\vv{u}\\\\ s.t.\\&gt;\\&gt; \\vv{u}^\\top\\vv{u}=1 \\]Solve it, we get \\[ \\mathbf{S}\\vv{u}=\\lambda\\vv{u}\\\\ \\lambda=\\vv{u}^\\top \\mathbf{S} \\vv{u} \\] Therefore \\(\\lambda\\) is the largest eigen-value.add more component\\[ \\hat{\\vv{u}}_2=\\text{argmax}_\\vv{u}\\vv{u}^\\top \\mathbf{S} \\vv{u}\\\\ s.t.\\&gt;\\&gt; \\vv{u}^\\top\\vv{u}=1 \\\\ \\&gt;\\&gt; \\vv{u}_1^\\top\\vv{u}=0 \\]\\[ \\mathbf{S} \\vv u_2 - \\lambda \\vv u_2 - \\gamma \\vv u_1=0\\\\ \\vv u_1^\\top \\mathbf{S} \\vv u_2 - 0 - \\gamma = 0\\\\ \\mathbf{S} \\vv u_2 - \\lambda \\vv u_2=0\\\\ \\lambda=\\vv u_2^\\top \\mathbf{S} \\vv u_2 \\]\\[ \\hat{\\vv\\mu_3}=\\text{argmax}_{\\mu_3}\\vv\\mu_3^\\top\\mathbf{S}\\vv\\mu_3\\\\ s.t. \\&gt;\\&gt; \\vv{\\mu_3}^\\top\\vv\\mu_3=1, \\vv\\mu_3^\\top\\vv\\mu_2=0, \\vv\\mu_3^\\top\\vv\\mu_1=0,\\vv\\mu_2^\\top\\vv\\mu_1=0 \\]\\[ \\mathbf S\\vv\\mu_3-\\lambda \\vv\\mu_3-\\gamma_2\\vv\\mu_2-\\gamma_1\\vv\\mu_1=0\\\\ \\vv\\mu_1^\\top\\mathbf{S}\\vv\\mu_3-0-0-\\gamma_1=0\\\\ \\vv\\mu_2^\\top\\mathbf{S}\\vv\\mu_3-0-\\gamma_2-0=0\\\\ \\therefore \\gamma_1=\\gamma_2=0\\\\ \\therefore \\mathbf{S}\\vv\\mu_3=\\lambda \\vv\\mu_3 \\\\ \\therefore \\vv\\mu_3^\\top\\mathbf{S}\\vv\\mu_3=\\lambda \\]Therefore \\(\\vv\\mu_2, \\vv\\mu_3\\) must be the eigenvector with 2nd and 3rd largest engienvalues.Minimum Error FormulationA set of complete orthonormal basis \\[ \\{\\vv u_1,\\vv u_2, ..., \\vv u_n\\} \\] Then \\(\\vv x\\) can be represented by \\(\\vv{x}=\\sum_i \\alpha_i \\vv u_i, \\alpha_i=\\vv{x}^\\top\\vv u_i\\)Consider a low-dimension representation: \\[ \\vv{x}_n=\\sum_{i=1}^{d}z_{ni}\\vv u_i + \\sum_{i=d+1}^{D}b_i\\vv u_i \\]\\[ J=\\frac{1}{N}\\sum_{n=1}^{N}||x_n-\\hat x_n||^2 \\]\\[ \\frac{dJ}{dz_{ni}}=2(x_n-\\sum_{i=1}^dz_{ni}u_i-\\sum_{i=d+1}^Db_iu_i)^\\top u_i=0\\\\ x_n^\\top u_i -z_{ni}=0 \\]\\[ \\frac{dJ}{db_i}=2\\sum_{n=1}^N(x_n-\\sum_{i=1}^dz_{ni}u_i-\\sum_{i=d+1}^Db_iu_i)^\\top u_i=0\\\\ \\sum_{n=1}^{N}x_n^\\top u_i-N b_i=0 \\]Therefore the error \\(J\\) equals \\[ J=\\sum_{n=1}^{N}\\sum_{i=d+1}^{D}((x_i-\\bar x)^\\top u_i)u_i\\\\ =\\sum_{i=d+1}^{D}u_i^\\top S u_i \\] It can be prove similarly that \\(u_i\\) should be the \\(D-d\\) smallest eigen-values' eigen-vectors. \\[ \\hat x_n = \\sum_{i=1}^{d}(x_n^\\top u_i + \\bar x ^\\top u_i - \\bar x ^\\top u_i)u_i + \\sum_{i=d+1}^{D}(\\bar x^\\top u_i)u_i\\\\ =\\bar x + \\sum_{i=1}^{d}(x_n-\\bar x)^\\top u_i u_i \\] Probabilistic PCALet \\(z\\) be a latent feature vector. We assume its prior \\(z\\sim N(0, I)\\)Assume that \\(x=Wz+\\mu+\\epsilon, \\epsilon\\sim N(0, \\sigma^2 I)\\)Therefore \\[ p(x|z)=N(x|Wz+\\mu, \\sigma^2I)\\\\ p(x)=\\int_zp(x|z)p(z)dz=N(x|\\mu, C=WW^\\top+\\sigma^2I) \\]\\[ C^{-1}=\\sigma^{-2} I-\\sigma^{-2}WM^{-1}W^\\top\\\\ M=W^\\top W+\\sigma^2I \\]\\[ p(z|x)=\\mathcal N(z|M^{-1}W^\\top(x-u), \\sigma^{-2}M) \\]Apply MLE on \\(p(x)\\) \\[ \\nabla_{u}p(x)=\\nabla_{u}-\\frac{Np}{2}\\log(2\\pi)-\\frac{N}{2}\\log|C|-\\frac{1}{2}\\sum_{n=1}^{N}(x_n-\\mu)^\\top C^{-1}(x_n-\\mu)\\\\ =C^{-1}\\sum_{n=1}^{N}(x_n-\\mu)=0\\\\ \\therefore \\mu=\\bar x \\]\\[ \\log p(x)=-\\frac{N}{2}(p\\log(2\\pi)+\\log|C|+tr(C^{-1}S)) \\]image-20190423153437444We can choose \\(R=I\\)Let \\(\\sigma^2\\to 0\\) \\[ \\mathbb{E}[z|x]=M^{-1}W^\\top(x-\\mu)\\\\ =(W^\\top W)^{-1}W(x-\\mu)=W(x-\\mu) \\]","categories":[{"name":"StatisticalMachineLearning","slug":"StatisticalMachineLearning","permalink":"https://blog.lizeyan.me/categories/StatisticalMachineLearning/"}],"tags":[]},{"title":"Kernel Density Estimation","slug":"StatisticalMachineLearning/kernel_density_estimation","date":"2020-03-27T09:10:54.092Z","updated":"2020-03-27T09:10:54.092Z","comments":true,"path":"StatisticalMachineLearning/kernel_density_estimation/","link":"","permalink":"https://blog.lizeyan.me/StatisticalMachineLearning/kernel_density_estimation/","excerpt":"","text":"KDEKernel density estimation (KDE) is a non-parametric way to estimate the probability distribution function (PDF) of a random variable.若 \\(\\{x_n, n=1,2,...n\\}\\) 为一列\\(iid\\)的样本，那么它的KDE是 \\[ \\hat f_h(x)=\\frac{1}{nh}\\sum_{i=1}^{n}K(\\frac{x-x_i}{h}) \\] \\(h\\)是bandwith，对KDE的结果有很大影响KDE示例Bandwidth的选择","categories":[{"name":"StatisticalMachineLearning","slug":"StatisticalMachineLearning","permalink":"https://blog.lizeyan.me/categories/StatisticalMachineLearning/"}],"tags":[]},{"title":"Clustering","slug":"StatisticalMachineLearning/clustering","date":"2020-03-27T09:10:54.088Z","updated":"2020-03-27T09:10:54.088Z","comments":true,"path":"StatisticalMachineLearning/clustering/","link":"","permalink":"https://blog.lizeyan.me/StatisticalMachineLearning/clustering/","excerpt":"","text":"Clusteringcluster means group objects into classes of similar objectsMinimize inter-class similarityMaximize intra-class similarityMetric SapceWhat is distance?\\(d(x, y) = d(y, x)\\)\\(d(x , y) \\ge 0\\) and \\(d(x, y)=0 \\Leftrightarrow x = y\\)\\(d(x,y)\\le d(x, z) + d(z, y)\\)Examples:(distance derived from) \\(p\\)-normedit distancehamming distanceCosine distanceNon-metric distances, e.g. DTW, perceptual lossK-MeansAlgorithmInitialize \\(\\mu_1, ..., \\mu_K\\)Repeat until no change happensExpectation: for each \\(k\\), \\(C_k=\\{i\\&gt;s.t.\\&gt; x_i\\text{ is closest to }\\mu_k\\}\\)Maximization: for each \\(k\\), update \\(\\mu_k=\\frac{1}{|C_k|}\\sum_{i\\in C_k}x_i\\)Optimization problem\\[ J=\\sum_{n=1}^{N}\\sum_{k=1}^{K}r_{nk}||x_n-\\mu_k||^2 \\\\ s.t. \\&gt;\\&gt; \\sum_{k=1}^{K}r_{nk}=1, r_{nk}\\in\\{0, 1\\}\\\\ \\mu_k=\\frac{\\sum_ix_i1_{r_{nk}=1}}{\\sum_i1_{r_{nk}=1}} \\]In each expection step, we keep \\(\\mu_k\\) fixed and optimize \\(J\\) with respect to \\(r_{nk}\\) It has closed form solution: \\[r_{nk}=\\begin{cases}1 &amp; k=\\text{argmin}_i ||x_n-\\mu_i||^2 \\\\ 0 &amp; otherwise\\end{cases}\\]​In each maimization step, we keep \\(r_{nk}\\) fixed and optimize \\(J\\) with respect to \\(\\mu_k\\)It has closed form solution: \\[ \\because \\frac{\\partial J}{\\partial \\mu_k}=\\sum_i2 r_{ik} (x_i-\\mu_k)=0\\\\ \\therefore \\mu_k=\\frac{\\sum_n x_nr_{nk}}{\\sum_n r_{nk}} \\]K-Means as Gradient DescentsGradient descent can be applied.Second oder gradient descent leads to the same update rule as k-means.Find a Good OptimumK-means leads to a local optimumfind a good start pointRun many times of k-means and choose a best one....Gaussian MixtureGaussianMLE for Gaussian leads to natual solutionsGaussian Mixture\\[ p(x)=\\sum_{k=1}^{K}\\pi_k\\mathcal{N}(x|\\mu_k, \\Sigma_k)\\\\ p(x|z_k=1)=\\mathcal{N}(x|\\mu_k, \\Sigma_k)\\\\ p(z)=\\prod_{k=1}^{K}\\pi_k^{z_k}, \\pi_k\\in[0, 1], \\sum_{k=1}^{K}\\pi_k=1 \\]\\[ \\mathcal{L}_0=\\log p(D)\\\\ =\\sum_{n=1}^{N}\\log(\\sum_{k=1}^{K}\\pi_k\\mathcal N(x|\\mu_k, \\Sigma_k)) \\]Here, we assume that \\(\\pi_k\\) uniformly dsitrbuted. However, we can use another prior like Dirichlet distribution. \\[ \\mathcal{L}_0=\\log p(D)\\\\ =\\sum_{n=1}^{N}\\log(\\sum_{k=1}^{K}p(\\pi_k)\\pi_k\\mathcal N(x|\\mu_k, \\Sigma_k)) \\]Because of the constraints, we should use Lagrange multiplier method: \\[ \\mathcal{L}=\\mathcal{L}_0+\\lambda(\\sum_{k=1}^{K}\\pi_k-1) \\]Before do MLE, let's first take a look at the posterior: \\[ p(z_k=1|x)=\\frac{p(x|z_k=1)p(z_k=1)}{p(x)}\\\\ =\\frac{\\pi_k\\mathcal{N}(x|\\mu_k, \\Sigma_k)}{\\sum_{i=1}^{K}\\pi_i\\mathcal{N}(x|\\mu_i, \\Sigma_i)} \\] Let \\(\\gamma(z_k)=p(z_k=1|x)\\)Then \\[ \\because \\frac{\\partial \\mathcal L}{\\partial \\mu_k} =-\\sum_{n=1}^{N}\\frac{\\pi_k\\mathcal N(x_n|\\mu_k, \\Sigma_k)}{\\sum_{j=1}^{K}\\pi_j\\mathcal{N}(x_n|\\mu_j,\\Sigma_j)}\\cdot \\Sigma_k^{-1}(x_n-\\mu_k)\\\\ =\\sum_{n=1}^{N}\\gamma(z_{nk})\\Sigma_k^{-1}(x_n-\\mu_k)=0 \\\\ \\therefore \\mu_k=\\frac{\\sum_{n=1}^{N}\\gamma(z_{nk})x_n}{\\sum_{n=1}^{N}\\gamma(z_{nk})} \\] \\(\\mu\\) looks like a weighted mean of \\(x\\), but it is not a closed form solution.Maximize \\(\\mathcal L\\) with respect to \\(\\Sigma\\) is difficult, so we optimize it with respect to \\(\\Sigma^{-1}\\), which will be denoted as \\(S\\) \\[ \\nabla_{S}\\mathcal{L}=\\sum_{n=1}^{N}\\frac{\\pi_k}{\\sum_{i=1}^{K}\\pi_i\\mathcal N(x_n|\\mu_i, \\Sigma_i)}\\nabla_SN(x_n|\\mu_k, \\Sigma_k) \\]\\[ \\frac{\\partial N(x_n|\\mu_k, \\Sigma_k)}{\\partial S}=\\frac{\\partial N(x_n|\\mu_k, \\Sigma_k)}{\\partial \\log N(x_n|\\mu_k, \\Sigma_k)}\\cdot\\frac{\\partial \\log N(x_n|\\mu_k, \\Sigma_k)}{\\partial S}\\\\ \\because \\frac{\\partial N(x_n|\\mu_k, \\Sigma_k)}{\\partial \\log N(x_n|\\mu_k, \\Sigma_k)}=N(x_n|\\mu_k, \\Sigma_k) \\\\ \\frac{\\partial \\log N(x_n|\\mu_k, \\Sigma_k)}{\\partial S}=\\frac{1}{2}\\frac{\\partial \\log|S|}{\\partial S}-\\frac{1}{2}\\cdot\\frac{\\partial (x_n-\\mu_k)^\\top S (x_n-\\mu_k)}{\\partial S}\\\\ =\\frac{S^*}{2|S|}-\\frac{1}{2}(x_n-\\mu_k)(x_n-\\mu_k)^\\top \\\\ =\\frac{1}{2}(\\Sigma_k-(x_n-\\mu_k)(x_n-\\mu_k)^\\top)\\\\ \\therefore \\frac{\\partial N(x_n|\\mu_k, \\Sigma_k)}{\\partial S}=\\frac{1}{2}N(x_n|\\mu_k, \\Sigma_k)(\\Sigma_k-(x_n-\\mu_k)(x_n-\\mu_k)^\\top) \\]\\[ \\nabla_{S}\\mathcal{L}=\\sum_{n=1}^{N}\\gamma(z_{nk})(\\Sigma_k-(x_n-\\mu_k)(x_n-\\mu_k)^\\top)=0 \\]\\[ \\Sigma_k=\\frac{\\sum_{n=1}^{N}\\gamma(z_{nk})(x_n-\\mu_k)(x_n-\\mu_k)^\\top}{\\sum_{n=1}^{N}\\gamma(z_{nk})} \\]\\[ \\because \\nabla_{\\pi_k}\\mathcal{L}=\\sum_{n=1}^{N}\\frac{N(x_n|\\mu_k, \\Sigma_k)}{\\sum_{i=1}^{K}\\pi_i\\mathcal N(x_n|\\mu_i, \\Sigma_i)}+\\lambda=0 \\\\ \\therefore \\lambda\\sum_{i=1}^{K}(\\pi_k)+\\sum_{n=1}^{N}\\gamma(z_{nk})=0 \\\\ \\therefore \\lambda = -N = - \\sum_{n=1}^{N}\\sum_{k=1}^{K}\\gamma(z_{nk}) \\\\ \\therefore \\pi_k=\\frac{N_k}{N}=\\frac{\\sum_{n=1}^{N}\\gamma(z_{nk})}{\\sum_{n=1}^{N}\\sum_{i=1}^{K}\\gamma(z_{ni})} \\]EM algorithmExpection:calulate \\(\\gamma(z_{nk})\\)Maximization:update \\(\\mu, \\Sigma, \\pi\\)Variational Inference\\[ \\log P(D)=\\sum_{n=1}^{N}\\log P(x_n)\\\\ =\\sum_{n=1}^{N}\\log (\\sum_{z_n}q(z_n)\\frac{p(z_n)p(x_n|z_n))}{q(z_n)}\\\\ =\\sum_{n=1}^{N}\\log \\mathbb{E}_q[\\frac{p(z_n)p(x_n|z_n))}{q(z_n)}]\\\\ \\ge\\sum_{n=1}^{N}\\mathbb{E}_q[\\log\\frac{p(z_n)p(x_n|z_n))}{q(z_n)}]\\\\ =\\sum_{n=1}^{N}\\mathbb{E}_q[\\log p(x_n, z_n)-\\log q(z_n)] \\]Let \\(\\mathcal{L}_1=\\sum_{n=1}^{N}\\mathbb{E}_q[\\log p(x_n, z_n)-\\log q(z_n)]\\)The gap between \\(\\log P(D)\\) and \\(\\mathcal L_1\\): \\[ \\mathcal{L_1}=\\sum_{n=1}^{N}\\mathbb{E}_q[\\log p(x_n, z_n)-\\log q(z_n)]\\\\ =\\sum_{n=1}^N\\mathbb{E}_q[\\log p(x_n)+\\log p(z_n|x_n)-\\log q(z_n)]\\\\ =\\log p(D)-KL[q(Z)||p(Z|D)] \\]image-20190419173117190Minimize the gap with respect to \\(p(z)\\): E \\[ \\because \\mathcal{L}=\\log p(D)-KL[p(Z)||p(Z|D)]\\\\ \\therefore q=\\text{argmax}_{q} \\mathcal{L}=\\text{argmin}_q KL[q(Z)||p(Z|D)]\\\\ \\therefore q(z_n)=p(z_n|x_n) \\] Maximize the lower bbound with respect to \\(\\Theta\\): MEM example: multinomial distributionimage-20190421141432302In the expectation step, we calculate the posterior \\[ \\gamma_{dk}=P(c_d=k|d)\\\\ =\\frac{p(d|c_d=k)p(k)}{p(d)}\\\\ =\\frac {\\pi_k\\frac{n_d!}{\\prod_wT_{dw}!}\\prod_w\\mu_{wk}^{T_{dw}}} {\\sum_{k&#39;} \\frac{n_d!}{\\prod_wT_{dw}!}\\prod_w\\mu_{wk&#39;}^{T_{dw}}} \\] In the maximization step, apply MLE with \\(\\gamma_{dk}\\) fixed. \\[ \\mathcal{L}_0=\\log P(D)\\\\ =\\sum_{d}\\log P(d)\\\\ =\\sum_{d}\\log(\\sum_k P(d|c_d=k)P(c_d=k)) \\]The lagrange function is that \\[ \\mathcal{L}=\\sum_{d}\\log(\\sum_k P(d|c_d=k)P(c_d=k))\\\\ -\\sum_k[\\lambda_k(\\sum_w\\mu_{wk}-1)]\\\\ -\\beta(\\sum_k \\pi_k-1) \\]\\[ \\frac{d \\mathcal{L}}{du_{wk}}=\\sum_d \\frac{p(d|c_d=k)p(c_d=k)\\cdot\\frac{T_{dw}}{\\mu_{wk}}} {\\sum_kp(d|c_d=k)p(c_d=k)}-\\lambda_k=0\\\\ \\therefore \\sum_w(\\sum_d\\gamma_{dk}T_{dw}-\\mu_{wk}\\lambda_k)\\\\ \\therefore \\sum_d\\gamma_{dk}T_d-\\lambda_k=0\\\\ \\therefore \\mu_{wk}=\\frac{\\sum_d\\gamma_{dk}T_{dw}}{\\sum_d\\gamma_{dk}T_d} \\]\\[ \\frac{d\\mathcal{L}}{d\\pi_k}=\\sum_d\\frac{P(d|c_d=k)}{\\sum_kP(d|c_d=k)P(d_d=k)}-\\beta=0\\\\ \\because \\sum_k(\\sum_d\\frac{P(d|c_d=k)\\pi_k}{\\sum_kP(d|c_d=k)P(d_d=k)}-\\pi_k\\beta)=0\\\\ \\therefore \\sum_k\\sum_d\\gamma_{dk}-\\beta=0\\\\ \\therefore \\beta=D\\\\ \\therefore \\sum_d\\gamma_{dl}-D\\pi_k=0\\\\ \\therefore \\pi_k=\\frac{\\sum_d\\gamma_{dk}}{D} \\]","categories":[{"name":"StatisticalMachineLearning","slug":"StatisticalMachineLearning","permalink":"https://blog.lizeyan.me/categories/StatisticalMachineLearning/"}],"tags":[{"name":"unsupervised","slug":"unsupervised","permalink":"https://blog.lizeyan.me/tags/unsupervised/"}]},{"title":"Unable to Access Host via PVE API","slug":"Proxmox Virtual Environment/unable_to_access_host","date":"2020-03-27T09:10:54.080Z","updated":"2020-03-27T09:10:54.080Z","comments":true,"path":"Proxmox Virtual Environment/unable_to_access_host/","link":"","permalink":"https://blog.lizeyan.me/Proxmox Virtual Environment/unable_to_access_host/","excerpt":"","text":"IssueHost is alive and accessible, but all vm states are not accessable, and web GUI is not accessable either.I can ssh to this host.12lsof -i :8006# there are processes listening on it12curl -s -k https://localhost:8006# nothing respond12tail /var/log/pveproxy/access.log# nothingSolution1service pve-cluster restart","categories":[{"name":"Proxmox Virtual Environment","slug":"Proxmox-Virtual-Environment","permalink":"https://blog.lizeyan.me/categories/Proxmox-Virtual-Environment/"}],"tags":[]},{"title":"Einstein Summation Convention","slug":"Python/Einstein-Summation-Convention","date":"2020-03-27T09:10:54.080Z","updated":"2020-03-27T09:10:54.080Z","comments":true,"path":"Python/Einstein-Summation-Convention/","link":"","permalink":"https://blog.lizeyan.me/Python/Einstein-Summation-Convention/","excerpt":"","text":"Common operations in this notation\\[ \\mathbf{u}\\cdot\\mathbf{v}=u_iv^i \\]\\[ \\mathbf{C}=\\mathbf{A}\\mathbf{B}\\\\ \\Rightarrow C^i_k=A^i_{j}B^{j}_k \\]\\[ trace(\\mathbf{A})=A^i_{i} \\]NumPy Convention\\(trace(A)\\): ii\\(diag(A)\\): ii-&gt;isum(A, axis=1): ij-&gt;i\\(A^\\top\\): ij-&gt;ji\\(\\mathbf{u}\\cdot\\mathbf{v}\\): i,i\\(\\mathbf{A}\\mathbf{u}\\): ij,j-&gt;i","categories":[{"name":"Python","slug":"Python","permalink":"https://blog.lizeyan.me/categories/Python/"}],"tags":[]},{"title":"boost","slug":"StatisticalMachineLearning/boost","date":"2020-03-27T09:10:54.080Z","updated":"2020-03-27T09:10:54.080Z","comments":true,"path":"StatisticalMachineLearning/boost/","link":"","permalink":"https://blog.lizeyan.me/StatisticalMachineLearning/boost/","excerpt":"","text":"Model Averaging: from CT to BoostingIn generally, Boosting &gt; Random Forest &gt; Bagging &gt; Single TreeClassification TreesThe decision boundaries are along the axes.BaggingSuppose \\(C(S, x)\\) is a classifier for dataset \\(S\\) and input point \\(x\\).To bag \\(C\\), draw bootstrap samples \\(S_1, S_2, ..., S_B\\) from \\(S\\) with size \\(N\\)\\(C_{\\text{bag}}(x)=\\text{Majority Vote}(C(S_i, x), i \\in [1, B])\\)Random Forestrefine baggingAt each tree split ,randomly sample \\(m\\) features and only consider these samples. Typically \\(m=\\sqrt p\\) or \\(m=\\log p\\), where \\(p\\) is the total number of features.RF tries to improve bagging by de-corelating the trees.sBoostingAverage many trees, but each grown from reweighed samples. \\[ C(x)=\\text{sign}\\sum_{n}\\alpha_nC_n(x) \\]Adaboostinitialize observations' weights \\(w_i=\\frac{1}{N}, i = 1, 2, ..., N\\)For m from 1 to M:fit \\(C_m\\) with observations with weights \\(w_i\\)Compute weighted error rate: \\[ err_m=\\frac{\\sum_i w_i1_{C_m(x_i)\\neq y_i}}{\\sum_i w_i} \\]Update ratio \\(\\alpha_m=\\log\\frac{1-err_m}{err_m}\\)Update weights \\[ w_i \\leftarrow w_i \\cdot \\exp(\\alpha_m1_{C_m(x_i)\\neq y_i}) \\]Renormalize sum of \\(w_i\\) to 1sreturn \\(C(x)=\\text{sign}(\\sum_{i=1}^{M}\\alpha_mC_m(x))\\)train_error_theoremAdditive ModelBoosting build a additive model: \\[ f(x)=\\sum_{k=1}^{M}\\beta_kC(x;\\gamma_k) \\] Traditional methods fit the parameters jointly. But Adaboost do it stagewisely.Adaboost: Stagewise ModelingAdaboost fit a stagewise logistic regression model \\(f(x)\\) by stagewisely fit the loss: \\[ \\mathcal{L}=\\exp(-yf(x)) \\]Given \\(f_{M-1}(x)\\), the solution to \\(\\beta_M, \\gamma_M\\) is \\[ \\text{argmin}_{\\beta, \\gamma}\\sum_{i=1}^{N}\\exp(-y_i(f_{M-1}(x_i)+\\beta C(x_i;\\gamma))) \\]Why Exponential Lossimage-20190419140355191exp loss is a upper bound of 0-1 loss.It leads to simple reweighting scheme.binomial deviance can be more robustGeneral Stagewise Algorithmimage-20190419140524731Learning from Crowds","categories":[{"name":"StatisticalMachineLearning","slug":"StatisticalMachineLearning","permalink":"https://blog.lizeyan.me/categories/StatisticalMachineLearning/"}],"tags":[]},{"title":"GAN Anomaly Detection","slug":"PaperNotes/gan_anomaly_detection","date":"2020-03-27T09:10:54.076Z","updated":"2020-03-27T09:10:54.076Z","comments":true,"path":"PaperNotes/gan_anomaly_detection/","link":"","permalink":"https://blog.lizeyan.me/PaperNotes/gan_anomaly_detection/","excerpt":"","text":"GANomaly: Semi-Supervised Anomaly Detection via Adversarial TrainingRef: Akcay, Samet, Amir Atapour-Abarghouei, and Toby P. Breckon. \"GANomaly: Semi-Supervised Anomaly Detection via Adversarial Training.\" arXiv preprint arXiv:1805.06725(2018).Real-Time Anomaly Detection and Localization in Crowded ScenesRef: Sabokrou, Mohammad, et al. \"Real-time anomaly detection and localization in crowded scenes.\" Proceedings of the IEEE conference on computer vision and pattern recognition workshops. 2015.","categories":[{"name":"PaperNotes","slug":"PaperNotes","permalink":"https://blog.lizeyan.me/categories/PaperNotes/"}],"tags":[]},{"title":"Network Diffusion","slug":"PaperNotes/network_diffusion","date":"2020-03-27T09:10:54.076Z","updated":"2020-03-27T09:10:54.076Z","comments":true,"path":"PaperNotes/network_diffusion/","link":"","permalink":"https://blog.lizeyan.me/PaperNotes/network_diffusion/","excerpt":"","text":"Network Diffusion[TOC]Invariant Network假设有N条时间序列，这N条时间序列之间的相关关系称为invariant link。这样的有invariant link的graph就称为invariant network。具体的做法是用ARX模型1。给定两个时间序列\\(x(t), y(t)\\)。若将\\(x\\)作为输入，那么记 \\[ \\phi(t)=[-y(t-1),...,-y(t-n),x(t-k),...,x(t-k-m)]^\\top\\\\ \\theta = [a_1,...,a_n,b_0,...,b_m]^\\top \\] 模型定义为\\(\\hat{y}(t)=\\phi(t)^\\top\\theta\\)。通过最小化MSE得，\\(\\theta\\)的解为 \\[ \\hat{\\theta}_N=[\\sum_{t=1}^{N}\\phi(t)\\phi(t)^\\top]^{-1}\\sum_{t=1}^{N}\\phi(t)y(t) \\] 定义fitness score为 \\[ F(\\theta)=1 - \\sqrt{\\frac{\\sum_{t=1}^{N}|y(t)-\\hat{y}(t)|^2}{\\sum_{t=1}^{N}|y(t)-\\bar{y}|^2}} \\] 如果\\(F(\\theta)\\)超过一个给定的阈值，那么就认为两个模型之间有相关关系。但是给定一组\\(x, y\\)，我们无法事先确定哪个是输入哪个是输出。2中的方法是选择\\(F(\\theta)\\)较高的那一个，但是同时要求两个模型的fitness score都比较高。Broken Links当系统发生异常时，组件之间的invariant link常常会发生变化。消失的invariant link就被称为broken link。通过检测哪些组件导致了broken link可以引导运维人员找到故障的根因。image-20190625152129817MRF ModelAlgorithmMRF（Markov random field）模型可以用来建模invariant network和borken network3。MRF包含若干个变量，每个变量有隐状态和显状态，隐状态之间有互相的连接。每个包含至少一条broken link的节点是MRF中的一个变量，broken link是变量之间的连接。其observed state是我们对每个节点的根因程度的直接观察。具体的定义可以为 \\[ RB_{v_i}=\\frac{number\\&gt;of\\&gt;borken\\&gt;links\\&gt;of\\&gt;v_i}{number\\&gt;of\\&gt;all\\&gt;links\\&gt;of\\&gt;v_i}\\\\ RUB_{v_i}=1-\\frac{number\\&gt;of\\&gt;broken\\&gt;links\\&gt;related\\&gt;to\\&gt;BINN}{number\\&gt;of\\&gt;all\\&gt;links\\&gt;related\\&gt;to\\&gt;BINN} \\] BINN指的是节点的通过broken link连接起来的邻居RB被用来作为隐状态的初始值，RUB作为显状态4。node compatibility function定义为 \\[ \\Phi(\\lambda, \\omega)=\\begin{cases}\\omega &amp; \\lambda=abnormal\\\\1-\\omega &amp; \\lambda =normal\\end{cases} \\] 每个节点是根因的belief，\\(b(\\lambda)\\)为： \\[ b_i(\\lambda)=k\\Phi(\\lambda, \\omega_i)\\prod_{j\\in N(i)}m_{ji}(\\lambda) \\] \\(m_{ji}(\\lambda)\\)表示邻居\\(j\\)认为\\(i\\)处于状态\\(\\lambda\\)的belief \\[ m_{ij}(\\lambda)=\\sum_{\\lambda&#39;}\\Phi(\\lambda,\\omega_i)\\Psi(\\lambda,\\lambda&#39;)\\prod_{n\\in N(i)/j}m_{ni}(\\lambda&#39;) \\] 其中\\(\\Psi(\\lambda,\\lambda&#39;)\\)表示edge compatibility function。normalabnormalnormal\\(\\epsilon_0\\) (很小)\\(1-\\epsilon_0\\)abnormal\\(\\epsilon\\) （小于0.5）\\(1-\\epsilon\\)这样的message passing的方法被称为loopy BP5。Evaluation~6中只把MRF model和直接用RB给节点排序的方法进行了对比。评价指标是top-k precision，top-k recall，和nDCG。Top-k precision and recall. k一般选择ground truth set大小的两倍 [^dcg]。nDCG （cumulated gain vector with discount, [^dcg]）：表征top-p的排序结果。p一半比ground truth set略小。 \\[ nDCG=\\frac{DCG}{IDDCG} \\] \\[ DCG_p=\\sum_{i=1}^{p}\\frac{2^{rel_i-1}}{\\log_2{1+i}} \\] ​ \\(rel_i\\)是第i名在ground truth中的名次。IDCG是ground truth的DCG但是从结果看来，LBP比直接用RB并不好太多。Benchmark是人工生成的。image-20190625151638557image-20190625151846712image-20190625151900114Label Propagation and Network Diffusion7Algorithm\\(\\mathbf{A}_{n\\times n}\\), \\(\\mathbf{P}_{n\\times n}\\)是原本的IN和broken IN的邻接矩阵。\\(\\mathbf{A}\\)的元素表示两个节点之间的相关性，比如fitness score。\\(\\mathbf{P}\\)的元素表示两个节点之间的不相关性，比如residual。故障传播模型指的是，给定每个节点是否（根因）异常的\\(\\mathbf{e}\\)，计算在IN上故障传播后每个节点的故障程度\\(\\mathbf{r}\\)。基本的假设是，故障沿着相关传播，\\(\\mathbf{A}_{ij}\\)越大（根据度normalized之后），那么关联的两个节点之间的\\(\\mathbf{r}_i, \\mathbf{r}_j\\)就应该越接近。即\\(\\mathbf{r}\\)在IN上是平滑的。另一个假设是\\(\\mathbf{e}\\)和\\(\\mathbf{r}\\)之间要尽量接近。 \\[ \\min_{\\mathbf{r}\\ge 0}c\\mathbf{r}^\\top(\\mathbf{1}-\\tilde{\\mathbf{A}})\\mathbf{r}+(1-c)||\\mathbf{r}-\\mathbf{e}||_2^2 \\]Network diffusion指的是衡量根因重构出来的broken IN和真实的broken IN的差别。 \\[ \\min_{\\mathbf{e}\\in \\{0, 1\\}^N}\\&gt;\\lambda||(\\mathbf{r}\\mathbf{r}^\\top)\\odot\\mathbf{M}-\\tilde{\\mathbf{P}}||_2^2 + c\\mathbf{r}^\\top(\\mathbf{1}-\\tilde{\\mathbf{A}})\\mathbf{r}+(1-c)||\\mathbf{r}-\\mathbf{e}||_2^2 \\] 松弛形式 \\[ \\min_{\\mathbf{e}\\ge0}\\&gt;\\lambda||(\\mathbf{r}\\mathbf{r}^\\top)\\odot\\mathbf{M}-\\tilde{\\mathbf{P}}||_2^2 + c\\mathbf{r}^\\top(\\mathbf{1}-\\tilde{\\mathbf{A}})\\mathbf{r}+(1-c)||\\mathbf{r}-\\mathbf{e}||_2^2 + \\tau||\\mathbf{e}||_1 \\] 上述优化问题的迭代解法参考了8image-20190625153725849Evaluation同样是在人工随机生成的500条time series上进行的实验。评价指标仍然是top-k precision，top-k recall和nDCG。除此之外还随机注入了broken link作为噪声，检验robustness。实验表明噪声比例多至0.5时性能才会有明显下降。Multiple Root Cause考虑到invariant network中会有不同的cluster，故障是在cluster内传播的。同时系统中可能有多个cluster同时发生了故障。因此9提出了基于聚类的故障定位方法CRD。Algorithm定义矩阵 \\(\\mathbf{U}_{n\\times k}\\)为cluster membership矩阵，\\(\\mathbf{U}_{xi}=p(i|x)， \\mathbf{U}\\mathbf{1}_{k}=\\mathbf{1}_n\\)。首先要使用正常的IN进行聚类。通过doubly schchastic matrix decomposition方法计算\\(\\mathbf{U}\\)。首先计算重构的邻接矩阵\\(\\hat{A}\\)。\\(\\hat{A}_{xy}=\\sum_{i=1}^{k}\\frac{\\mathbf{U_{xi}\\mathbf{U}_{yi}}}{\\sum_{z=1}^n\\mathbf{U}_{zi}}\\)然后优化\\(A\\)和\\(\\hat{A}\\)的KL散度 \\(D_{KL}[A||\\hat{A}]\\)通过给\\(\\mathbf{U}\\)指定Dirichlet先验，使得可以得到尽量稀疏的\\(\\mathbf{U}\\)。然后需要使用broken IN进行聚类。Intuition是如果两个节点在同一个发生故障的cluster中，那么他们之间更可能出现broken link。定义参数\\(s_i\\)表示一个cluster的异常程度。 \\[ \\mathbf{P}_{xy}\\sim Bernoulli(\\sum_{i=1}^{k}\\mathbf{U}_{xi}\\mathbf{U}_{yi}s_i) \\] 然后通过MLE学习\\(\\mathbf{U}\\)和\\(\\mathbf{s}\\)。以上的两个聚类方法通过联合优化的方法可以一起进行。定义\\(E_{xi}=1\\)表示节点\\(x\\)是cluster \\(i\\)的根因。仿照10的推导，可以得到 \\[ \\min_{\\mathbf{E}\\ge0}\\&gt;||(\\mathbf{H}(\\mathbf{U}\\odot\\mathbf{E})(\\mathbf{U}\\odot\\mathbf{E})^\\top\\mathbf{H})\\odot M - \\tilde{\\mathbf{P}}||_2^2 + \\tau||\\mathbf{E}||_1 \\] 其中\\(\\mathbf{H}=(1-c)(\\mathbf{I}-c\\tilde{\\mathbf{A}})^{-1}\\)最后的rank score是\\(f_x=\\sum_{i=1}^{k}\\mathbf{U}_{xi}\\odot\\mathbf{E}_{xi} \\cdot s_i\\)Evaluation数据集是BIS。1112中也用了这个数据集进行定性的评测，但是没有找到公开的下载地址。Guofei Jiang, Haifeng Chen, K. Yoshihira. Efficient and Scalable Algorithms for Inferring Likely Invariants in Distributed Systems↩Guofei Jiang, Haifeng Chen, K. Yoshihira. Efficient and Scalable Algorithms for Inferring Likely Invariants in Distributed Systems↩Changxia Tao, Yang Ge, Qinbao Song, Yuan Ge, Olufemi A. Omitaomu. Metric Ranking of Invariant Networks with Belief Propagation.↩Changxia Tao, Yang Ge, Qinbao Song, Yuan Ge, Olufemi A. Omitaomu. Metric Ranking of Invariant Networks with Belief Propagation.↩Changxia Tao, Yang Ge, Qinbao Song, Yuan Ge, Olufemi A. Omitaomu. Metric Ranking of Invariant Networks with Belief Propagation.↩Changxia Tao, Yang Ge, Qinbao Song, Yuan Ge, Olufemi A. Omitaomu. Metric Ranking of Invariant Networks with Belief Propagation.↩Wei Cheng, Kai Zhang, Haifeng Chen, Guofei Jiang, Zhengzhang Chen, Wei Wang. Ranking Causal Anomalies via Temporal and Dynamical Analysis on Vanishing Correlations↩Chris Ding , Tao Li , Wei Peng , Haesun Park, Orthogonal nonnegative matrix t-factorizations for clustering, Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, August 20-23, 2006, Philadelphia, PA, USA↩Ranking Causal Anomalies by Modeling Local Propagations on Networked Systems, ICDM 2017↩Wei Cheng, Kai Zhang, Haifeng Chen, Guofei Jiang, Zhengzhang Chen, Wei Wang. Ranking Causal Anomalies via Temporal and Dynamical Analysis on Vanishing Correlations↩Changxia Tao, Yang Ge, Qinbao Song, Yuan Ge, Olufemi A. Omitaomu. Metric Ranking of Invariant Networks with Belief Propagation.↩Wei Cheng, Kai Zhang, Haifeng Chen, Guofei Jiang, Zhengzhang Chen, Wei Wang. Ranking Causal Anomalies via Temporal and Dynamical Analysis on Vanishing Correlations↩","categories":[{"name":"PaperNotes","slug":"PaperNotes","permalink":"https://blog.lizeyan.me/categories/PaperNotes/"}],"tags":[]},{"title":"Train GAN","slug":"PaperNotes/train_gan","date":"2020-03-27T09:10:54.076Z","updated":"2020-03-27T09:10:54.076Z","comments":true,"path":"PaperNotes/train_gan/","link":"","permalink":"https://blog.lizeyan.me/PaperNotes/train_gan/","excerpt":"","text":"Towards Principled Methods for Training Generative Adversarial NetworksRef: Arjovsky, M., Bottou, L.: Towards Principled Methods for Training Generative Adversarial Networks. In: 2017 ICLR (April 2017), http://arxiv.org/abs/ 1701.04862Improved techniques for training gansRef","categories":[{"name":"PaperNotes","slug":"PaperNotes","permalink":"https://blog.lizeyan.me/categories/PaperNotes/"}],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://blog.lizeyan.me/tags/GAN/"},{"name":"train GAN","slug":"train-GAN","permalink":"https://blog.lizeyan.me/tags/train-GAN/"}]},{"title":"Dreaming Dogs","slug":"Dreaming Dogs/What is Dreaming Dogs","date":"2020-03-27T09:10:54.072Z","updated":"2020-03-27T09:10:54.072Z","comments":true,"path":"Dreaming Dogs/What is Dreaming Dogs/","link":"","permalink":"https://blog.lizeyan.me/Dreaming Dogs/What is Dreaming Dogs/","excerpt":"","text":"","categories":[{"name":"Dreaming Dogs","slug":"Dreaming-Dogs","permalink":"https://blog.lizeyan.me/categories/Dreaming-Dogs/"}],"tags":[]},{"title":"cjk","slug":"Latex/cjk","date":"2020-03-27T09:10:54.072Z","updated":"2020-03-27T09:10:54.072Z","comments":true,"path":"Latex/cjk/","link":"","permalink":"https://blog.lizeyan.me/Latex/cjk/","excerpt":"","text":"12345678910111213\\documentclass&#123;article&#125;\\usepackage&#123;CJKutf8&#125;\\begin&#123;document&#125;\\begin&#123;CJK*&#125;&#123;UTF8&#125;&#123;gbsn&#125;\\section&#123;某章&#125;内容\\section&#123;某章&#125;内容\\clearpage\\end&#123;CJK*&#125;\\end&#123;document&#125;","categories":[{"name":"Latex","slug":"Latex","permalink":"https://blog.lizeyan.me/categories/Latex/"}],"tags":[]},{"title":"LaTex Snippets","slug":"Latex/latex_snippets","date":"2020-03-27T09:10:54.072Z","updated":"2020-03-27T09:10:54.072Z","comments":true,"path":"Latex/latex_snippets/","link":"","permalink":"https://blog.lizeyan.me/Latex/latex_snippets/","excerpt":"","text":"123456789101112131415161718192021222324252627282930313233343536373839404142434445464748% preamble.tex% simple macros for replacement\\newcommand&#123;\\IE&#125;&#123;\\textit&#123;i.e.&#125;&#125;\\newcommand&#123;\\EG&#125;&#123;\\textit&#123;e.g.&#125;&#125;\\newcommand&#123;\\WRT&#125;&#123;\\textit&#123;w.r.t.&#125;&#125;% macros for math\\newcommand&#123;\\dd&#125;&#123;\\mathrm&#123;d&#125;&#125;\\newcommand&#123;\\vv&#125;[1]&#123;\\bm&#123;\\mathrm&#123;&#123;#1&#125;&#125;&#125;&#125;\\newcommand&#123;\\E&#125;&#123;\\operatorname&#123;\\mathbb&#123;E&#125;&#125;&#125;\\newcommand&#123;\\EE&#125;[1]&#123;\\operatorname&#123;\\mathbb&#123;E&#125;&#125;\\left[&#123;#1&#125;\\right]&#125;\\newcommand&#123;\\EEE&#125;[2]&#123;\\operatorname&#123;\\mathbb&#123;E&#125;&#125;_&#123;&#123;#1&#125;&#125;\\left[&#123;#2&#125;\\right]&#125;\\newcommand&#123;\\Var&#125;&#123;\\operatorname&#123;Var&#125;&#125;\\newcommand&#123;\\Varr&#125;[1]&#123;\\operatorname&#123;Var&#125;\\left[&#123;#1&#125;\\right]&#125;\\newcommand&#123;\\Varrr&#125;[2]&#123;\\operatorname&#123;Var_&#123;&#123;#1&#125;&#125;&#125;\\left[&#123;#2&#125;\\right]&#125;\\newcommand&#123;\\KLD&#125;&#123;\\operatorname&#123;KL&#125;&#125;\\newcommand&#123;\\KLDD&#125;[2]&#123;\\operatorname&#123;KL&#125;\\left[&#123;#1&#125;\\,\\big\\|\\,&#123;#2&#125;\\right]&#125;\\newcommand&#123;\\abs&#125;[1]&#123;\\left|#1\\right|&#125;\\newcommand&#123;\\Entropy&#125;&#123;\\operatorname&#123;H&#125;&#125;\\newcommand&#123;\\Entropyy&#125;[1]&#123;\\operatorname&#123;H&#125;\\left[#1\\right]&#125;%\\newcommand&#123;\\T&#125;&#123;&#123;\\small \\mathrm&#123;T&#125;&#125;&#125;\\newcommand&#123;\\anomalyprob&#125;&#123;\\operatorname&#123;\\hat&#123;P&#125;&#125;&#125;\\newcommand&#123;\\TP&#125;[0]&#123;\\text&#123;TP&#125;&#125;\\newcommand&#123;\\TN&#125;[0]&#123;\\text&#123;TN&#125;&#125;\\newcommand&#123;\\FP&#125;[0]&#123;\\text&#123;FP&#125;&#125;\\newcommand&#123;\\FN&#125;[0]&#123;\\text&#123;FN&#125;&#125;\\newcommand&#123;\\argmax&#125;[0]&#123;\\text&#123;argmax&#125;&#125;\\newcommand&#123;\\argmin&#125;[0]&#123;\\text&#123;argmin&#125;&#125;\\newcommand&#123;\\diag&#125;[0]&#123;\\text&#123;diag&#125;&#125;\\newcommand&#123;\\dev&#125;[1]&#123;\\textcolor&#123;red&#125;&#123;#1&#125;&#125;\\newcommand&#123;\\ignore&#125;[1]&#123;\\iffalse#1\\fi&#125;% reference\\crefname&#123;chapter&#125;&#123;Chapter&#125;&#123;Chapters&#125;\\crefname&#123;figure&#125;&#123;Fig.&#125;&#123;Figs&#125;\\crefname&#123;equation&#125;&#123;Eqn.&#125;&#123;Eqns&#125;\\crefname&#123;table&#125;&#123;Table&#125;&#123;Tables&#125;\\crefformat&#123;section&#125;&#123;$\\S&#123;&#125;$#2#1#3&#125;\\crefformat&#123;subsection&#125;&#123;$\\S&#123;&#125;$#2#1#3&#125;\\crefformat&#123;subsubsection&#125;&#123;$\\S&#123;&#125;$#2#1#3&#125;\\newcommand&#123;\\BR&#125;[0]&#123;\\\\~\\\\&#125;\\newcommand&#123;\\tab&#125;[1]&#123;~~~~#1&#125;","categories":[{"name":"Latex","slug":"Latex","permalink":"https://blog.lizeyan.me/categories/Latex/"}],"tags":[]},{"title":"Bash Redirect Output","slug":"Linux/bash_redirect_output","date":"2020-03-27T09:10:54.072Z","updated":"2020-03-27T09:10:54.072Z","comments":true,"path":"Linux/bash_redirect_output/","link":"","permalink":"https://blog.lizeyan.me/Linux/bash_redirect_output/","excerpt":"","text":"Redirect output to fileShow interminalterminalfilefilemodeSyntaxStdOutStdErrStdOutStdErrmode&gt;noyesyesnooverwrite&gt;&gt;noyesyesnoappend2&gt;yesnonoyesoverwrite2&gt;&gt;yesnonoyesappend&amp;&gt;nonoyesyesoverwrite&amp;&gt;&gt;nonoyesyesappend| teeyesyesyesnooverwrite| tee -ayesyesyesnoappendn.e. (*)yesyesnoyesoverwriten.e. (*)yesyesnoyesappend|&amp; teeyesyesyesyesoverwrite|&amp; tee -ayesyesyesyesappend","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.lizeyan.me/categories/Linux/"}],"tags":[]},{"title":"Ubuntu 18.04 install notes","slug":"Linux/ubuntu_1804_install_notes","date":"2020-03-27T09:10:54.072Z","updated":"2020-03-27T09:10:54.072Z","comments":true,"path":"Linux/ubuntu_1804_install_notes/","link":"","permalink":"https://blog.lizeyan.me/Linux/ubuntu_1804_install_notes/","excerpt":"","text":"Post Install NotesCapslock Acts like Mac StyleGnome Tweak ToolKeyboard &amp; MouseAdditional layout optionsSwitch to another layoutMake sure only Capslock checkedXRDP1234567891011sudo apt install -y xrdpsudo sed -e 's/^new_cursors=true/new_cursors=false/g' \\ -i /etc/xrdp/xrdp.inisudo systemctl restart xrdpD=/usr/share/ubuntu:/usr/local/share:/usr/share:/var/lib/snapd/desktopcat &lt;&lt;EOF &gt; ~/.xsessionrcexport GNOME_SHELL_SESSION_MODE=ubuntuexport XDG_CURRENT_DESKTOP=ubuntu:GNOMEexport XDG_DATA_DIRS=$&#123;D&#125;export XDG_CONFIG_DIRS=/etc/xdg/xdg-ubuntu:/etc/xdgEOFmodify /etc/xrdp/startvm.sh123456789101112131415161718192021222324252627282930313233343536#!/bin/sh# xrdp X session start script (c) 2015, 2017 mirabilos# published under The MirOS Licenceif test -r /etc/profile; then . /etc/profilefiif test -r /etc/default/locale; then . /etc/default/locale test -z \"$&#123;LANG+x&#125;\" || export LANG test -z \"$&#123;LANGUAGE+x&#125;\" || export LANGUAGE test -z \"$&#123;LC_ADDRESS+x&#125;\" || export LC_ADDRESS test -z \"$&#123;LC_ALL+x&#125;\" || export LC_ALL test -z \"$&#123;LC_COLLATE+x&#125;\" || export LC_COLLATE test -z \"$&#123;LC_CTYPE+x&#125;\" || export LC_CTYPE test -z \"$&#123;LC_IDENTIFICATION+x&#125;\" || export LC_IDENTIFICATION test -z \"$&#123;LC_MEASUREMENT+x&#125;\" || export LC_MEASUREMENT test -z \"$&#123;LC_MESSAGES+x&#125;\" || export LC_MESSAGES test -z \"$&#123;LC_MONETARY+x&#125;\" || export LC_MONETARY test -z \"$&#123;LC_NAME+x&#125;\" || export LC_NAME test -z \"$&#123;LC_NUMERIC+x&#125;\" || export LC_NUMERIC test -z \"$&#123;LC_PAPER+x&#125;\" || export LC_PAPER test -z \"$&#123;LC_TELEPHONE+x&#125;\" || export LC_TELEPHONE test -z \"$&#123;LC_TIME+x&#125;\" || export LC_TIME test -z \"$&#123;LOCPATH+x&#125;\" || export LOCPATHfiif test -r /etc/profile; then . /etc/profilefi# test -x /etc/X11/Xsession &amp;&amp; exec /etc/X11/Xsession# exec /bin/sh /etc/X11/Xsession# exec /bin/sh /usr/bin/gnome-sessionexec /usr/bin/gnome-sessionset the RDP client to 32-bit color modeSambaYou must add smb user rather than use linux use directly1sudo smbpasswd -a username","categories":[{"name":"Linux","slug":"Linux","permalink":"https://blog.lizeyan.me/categories/Linux/"}],"tags":[]},{"title":"GAN","slug":"PaperNotes/gan","date":"2020-03-27T09:10:54.072Z","updated":"2020-03-27T09:10:54.076Z","comments":true,"path":"PaperNotes/gan/","link":"","permalink":"https://blog.lizeyan.me/PaperNotes/gan/","excerpt":"","text":"GANGoodfellow, Pouget-Abadie and in neural …, M. 2014. Generative adversarial nets. (2014).\\[ V(G,D)=\\mathbb{E}_{\\boldsymbol x \\sim p_\\text{data}({\\boldsymbol x})}[\\log D(\\boldsymbol x)] + \\mathbb{E}_{\\boldsymbol z\\sim p_\\boldsymbol z(\\boldsymbol z)}[\\log(1-D(G(z)))] \\]Training objective: \\[ \\min_G \\max_D V(G, D) \\]For any \\(G\\), optimal D is \\(D_G^*=\\frac{p_{data}}{p_{data}+p_g}\\)Since \\(V(G,D)=\\int p_{data}(\\boldsymbol x)\\log D(\\boldsymbol x)+p_g(\\boldsymbol x)\\log (1 - D(\\boldsymbol x)) d\\boldsymbol x\\)Then \\[ C(G)=V(G, D_G^*)=\\mathbb{E}_{\\boldsymbol x\\sim p_{data}}[\\log\\frac{p_{data}}{p_{data}+p_g}]+\\mathbb{E}_{\\boldsymbol x \\sim p_g}[\\log\\frac{p_g}{p_{data}+p_g}] \\] The global optimal for \\(V(G)\\) is \\(p_g^*=p_{data}\\)Since \\(C(G^*)=-\\log4\\), and \\[ C(G)=-\\log4+\\mathbb{KL}[p_{data}||\\frac{p_{data}+p_g}{2}]+\\mathbb{KL}[p_g||\\frac{p_{data}+p_g}{2}]\\\\ =-\\log4+2\\cdot JSD(p_{data}||p_g) \\]Convergence:If G and D have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given G, and p g is updated so as to improve the criterion \\(C(G)\\) then \\(p_g\\) converges to \\(p_{data}\\)Saturates:In practice, \\(V(G, D)\\) may not provide sufﬁcient gradient for \\(G\\) to learn well. Early in learning, when \\(G\\) is poor, \\(D\\) can reject samples with high conﬁdence because they are clearly different from the training data. In this case, \\(\\log(1 − D(G(\\boldsymbol z)))\\) saturates. Rather than training \\(G\\) to minimize \\(\\log(1 − D(G(\\boldsymbol z)))\\) we can train \\(G\\) to maximize \\(\\log D(G(\\boldsymbol z))\\). This objective function results in the same ﬁxed point of the dynamics of \\(G\\) and \\(D\\) but provides much stronger gradients early in learning.Training algorithm:image-20181217160009859WGAN","categories":[{"name":"PaperNotes","slug":"PaperNotes","permalink":"https://blog.lizeyan.me/categories/PaperNotes/"}],"tags":[{"name":"GAN","slug":"GAN","permalink":"https://blog.lizeyan.me/tags/GAN/"}]},{"title":"Page Rank","slug":"Algorithm/pagerank","date":"2020-03-27T09:10:54.068Z","updated":"2020-03-27T09:10:54.068Z","comments":true,"path":"Algorithm/pagerank/","link":"","permalink":"https://blog.lizeyan.me/Algorithm/pagerank/","excerpt":"","text":"PageRank记故障传播矩阵为\\(\\mathbf{A}^{N\\times N}\\)，每个节点的异常度\\(\\mathbf{u}\\)作为 personalization vector。 则 \\[ \\mathbf{\\pi}^\\top=\\mathbf{\\pi}^\\top(\\alpha \\mathbf{A}+(1-\\alpha)\\mathbf{e}\\mathbf{u}^\\top) \\] 因为\\(\\mathbf{\\pi}^\\top\\mathbf{e}=1\\)， 所以等价于 \\[ \\mathbf{\\pi}^\\top=\\alpha\\mathbf{\\pi}^\\top \\mathbf{A}+(1-\\alpha)\\mathbf{u}^\\top \\]记\\(\\mathbf{M}=(\\alpha \\mathbf{A}+(1-\\alpha)\\mathbf{e}\\mathbf{u}^\\top)\\) 则\\(\\mathbf{\\pi}\\)应为\\(\\mathbf{M}^\\top\\)的特征值为1 的特征向量。 因为\\(\\mathbf{M}\\mathbf{e}=\\mathbf{e}\\)，所以\\(\\mathbf{M}\\)有特征值 1，那么\\(\\mathbf{M}^\\top\\)也有根据Gershgorin circle theorem，\\(\\mathbf{M}^\\top\\)的最大特征值不超过 1所以只要找到\\(\\mathbf{M}\\)最大特征值对应的特征向量即可Gershgorin circle theorem 对于矩阵\\(\\mathbf{M}=(m_{ij})\\)，记\\(R_i=\\sum_{j\\neq i}|m_{ij}|\\)，则\\(\\mathbf{M}\\)的特征值至少在以下一个圆盘中：\\(D(m_{ii}, R_i), \\forall i\\) 证明： 记\\(\\lambda\\)是\\(\\mathbf{M}\\)的任意一个特征值，\\(\\mathbf{x}\\)是对应的特征向量，且使得模最大的元素的模正好是 1（这显然总是可以做到的），记为\\(x_i\\)。 那么\\(\\sum_jm_{ij}x_j=\\lambda x_i\\) 因为\\(x_i=1\\)，所以\\(\\sum_{j\\neq i}m_{ij}x_j+m_{ii}=\\lambda\\) 所以 \\[ |\\lambda-m_{ii}|=|\\sum_{j\\neq i}m_{ij}x_{ij}|\\le \\sum_{j\\neq i}|m_{ij}||x_j|\\le R_i \\]","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.lizeyan.me/categories/Algorithm/"}],"tags":[]},{"title":"Sequential Pattern Mining","slug":"Algorithm/sequential_pattern_mining","date":"2020-03-27T09:10:54.068Z","updated":"2020-03-27T09:10:54.068Z","comments":true,"path":"Algorithm/sequential_pattern_mining/","link":"","permalink":"https://blog.lizeyan.me/Algorithm/sequential_pattern_mining/","excerpt":"","text":"Sequential Pattern MiningSequenceA sequence is an ordered list of itemsets.\\(\\alpha\\) is called a subseuquence of \\(\\beta\\), denoted as \\(\\alpha \\subseteq \\beta\\), if there exist indices \\(1\\le j_1 \\le j_2 \\le ... \\le j_n\\le m\\), such that \\(\\alpha_1 \\subseteq b_{j_1}, ...., a_n\\subseteq b_{j_n}\\).SIDSequence1&lt;{a}, {a,b,c},{a,c},{d}, {c,f}&gt;2&lt;{a,d},{c},{b,c},{a,e}&gt;3&lt;{e,f},{a,b},{d,f},{c},{b}&gt;4&lt;{e},{g},{a,f},{c},{b},{c}&gt;Then &lt;{a,b}, {c}&gt; is a sequential pattern with support=2.Mining AlgorithmsApriori-Based AlgorithmsGSPSPADEPattern-Growth-Based ApproachesFreeSpanPrefixSpanThe Apriori PropertyIf a sequence is not frequent, then none of its super-sequence can be frequent.GSPreferenceInitialize candidates with all length-1 itemset. Set k = 1.Scan the databse once, count supports for all length-k candidates. Prune these candidates with a minimum support threshold.Generate length-(k+1) candidates. We remove the first and last item from each length-k candidates. If any two candiates' -1st and -last match, them we join them. k=k+1. Goto 2.SPADEAs GSP, SPADE also generates candidates and test their supports, but SPADE uses vertical sequence format.The advantage of vertical format is that it is easy to count support for new candidates.For example, &lt;ab&gt; is a new sequence generated by &lt;a&gt; and &lt;b&gt;, then we can get the support of &lt;ab&gt; joining the representations of &lt;a&gt; and &lt;b&gt;.image-20190718161458438PrefixSpanDefinition of prefix and suffix:Let sequence s=&lt;a, abc, ac, d, cf&gt;, then &lt;a&gt;, &lt;a,a&gt;, &lt;a, ab&gt;, &lt;a, abc&gt; are prefixes of s. The coresponding suffixes are &lt;abc, ac, d, cf&gt;, &lt;_bc, ac, d, cf&gt;, &lt;_c, ac, d, cf&gt;, &lt;ac, d, cf&gt;,Find all length-1 sequential patterns with database scaning.Partition the search space. Any sequential pattern must have one length-1 sequential pattern prefix.Recursively span sequential patterns.CloSpanMining closed sequential pattern only.Equivalence of projected databases:Two projected sequence databases \\(S|_\\alpha=S|_\\beta\\) , \\(\\alpha\\subseteq \\beta\\), are equivalent if and only if they contains the same number of items.","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.lizeyan.me/categories/Algorithm/"}],"tags":[]},{"title":"t-SNE","slug":"Algorithm/tsne","date":"2020-03-27T09:10:54.068Z","updated":"2020-03-27T09:10:54.068Z","comments":true,"path":"Algorithm/tsne/","link":"","permalink":"https://blog.lizeyan.me/Algorithm/tsne/","excerpt":"","text":"IntroSNEInput: \\[ \\{\\mathbf{x}_i, \\mathbf{x}_i\\in \\mathbb{R}^D\\}_{i=1}^{N} \\] Output: \\[ \\{\\mathbf{y}_i, \\mathbf{y}_i\\in \\mathbb{R}^d\\}_{i=1}^{N}, d&lt;D \\] ObjectiveSNE uses a conditional likelihood to measure the distance between two points, \\(p_{i|j}\\), which represents the probability to pick \\(j\\) when \\(i\\) is chosen. \\[ p_{j|i}=\\frac{\\exp(-\\frac{||\\mathbf{x}_i-\\mathbf{x}_j||^2}{2\\sigma_i^2})}{\\sum_{k\\neq i}\\exp(-\\frac{||\\mathbf{x}_i-\\mathbf{x}_k||^2}{2\\sigma_i^2})} \\] Similarly, in the low dimension space, SNE uses \\(q_{j|i}\\) to measure the distance between two mapping points. \\[ q_{j|i}=\\frac{\\exp(-||\\mathbf{y}_i-\\mathbf{y}_j||^2)}{\\sum_{k\\neq i}\\exp(-||\\mathbf{y}_i-\\mathbf{y}_k||^2)} \\] The objective function is to minimize the KL divergence between the distance distribution of original space and mapping space. \\[ C=\\text{KL}[P||Q]=\\sum_i \\sum_j p_{j|i}(\\log{p_{j|i}}-\\log{q_{j|i}}) \\] Estimation of \\(\\sigma_i\\)OptimizationGradient descent with momentum.t-SNE","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.lizeyan.me/categories/Algorithm/"}],"tags":[]},{"title":"","slug":"Conference/ISSRE","date":"2020-03-27T09:10:54.068Z","updated":"2020-03-27T09:10:54.068Z","comments":true,"path":"Conference/ISSRE/","link":"","permalink":"https://blog.lizeyan.me/Conference/ISSRE/","excerpt":"","text":"","categories":[{"name":"Conference","slug":"Conference","permalink":"https://blog.lizeyan.me/categories/Conference/"}],"tags":[]},{"title":"Optimization","slug":"DeepLearningBook/optimization","date":"2020-03-27T09:10:54.068Z","updated":"2020-03-27T09:10:54.068Z","comments":true,"path":"DeepLearningBook/optimization/","link":"","permalink":"https://blog.lizeyan.me/DeepLearningBook/optimization/","excerpt":"","text":"8.1 深度学习中的学习和纯优化问题有何不同机器学习通常不能用直接的方式学习。我们的目标是某个性能指标\\(P\\)，但是\\(P\\)是和测试集有关的，而且可能本身就是intractable的。为此我们通常是定义一个损失函数\\(J\\)，希望优化\\(J\\)能够提升\\(P\\)。我们的目标是优化在真实数据分布下的期望损失:$$ \\newcommand{\\vv}[1]{\\boldsymbol{#1}} J^{*}(\\vv \\theta)=\\mathbb{E}_{p_{data}}[\\mathcal{L}(f(\\vv{x};\\vv{\\theta}), \\vv{y})] $$经验风险在机器学习问题中，我们是不知道真实数据分布的，我们只有有限个数据样本，这些数据样本的经验分布为\\(\\hat p_{data}\\)。因此我们只能优化经验风险: \\[ \\mathbb{E}_{\\vv{x}\\sim \\hat p_{data}}[\\mathcal{L}(f(\\vv{x};\\vv{\\theta}), \\vv{y})] \\]但是经验风险有两个问题：经验风险容易过拟合。容量足够大的模型往往可以直接记住整个训练集。常用的高效的优化方法都是基于梯度的。但是准确的损失函数，比如0-1损失函数，往往无法提供梯度。替代损失函数和early stopping用来替代准确的损失函数，提供梯度信息的损失函数被称为surrogate loss。比如我们一般使用NLL替代0-1损失函数。替代损失函数可能会取得更好的性能，比如在0-1损失已经是0的时候，NLL还可以继续优化。因为即使我们找到了完美的分界面，我们还可以继续优化使得不同类数据分得尽量开。另一方面的差别是机器学习中一般不会令学习在达到局部极小点才终止。也就是early stopping技术。在验证集上我们可以使用准确的0-1 loss，当验证集上损失不在下降就可以停止训练。在往后训练就会发生过拟合，但此时训练集上梯度往往还比较大。minibatch估计梯度为以下的过程： \\[ \\nabla J =\\mathbb{E}_{\\hat p_{data}}[\\nabla \\mathcal{L}(f(\\vv{x};\\vv{\\theta}), \\vv{y})] \\]","categories":[{"name":"DeepLearningBook","slug":"DeepLearningBook","permalink":"https://blog.lizeyan.me/categories/DeepLearningBook/"}],"tags":[]},{"title":"Regularization","slug":"DeepLearningBook/regularization","date":"2020-03-27T09:10:54.068Z","updated":"2020-03-27T09:10:54.068Z","comments":true,"path":"DeepLearningBook/regularization/","link":"","permalink":"https://blog.lizeyan.me/DeepLearningBook/regularization/","excerpt":"","text":"RegularizationParamter Norm PenaltiesL2 NormL2正则化也被称为ridge回归或者Tikhonov回归假设参数只有权重\\(\\boldsymbol{w}\\)，正则化系数为\\(\\alpha\\)，则$$ \\newcommand{\\vv}[1]{\\boldsymbol{#1}} \\hat{J}=J+\\frac{1}{2}\\alpha \\vv{w}^\\top\\vv{w} \\\\ \\nabla{\\hat{J}}=\\nabla{J}+\\alpha \\vv{w} $$ $$ \\vv{w}\\leftarrow \\vv{w}-\\epsilon (\\alpha \\vv{w}+\\nabla J) \\\\ \\Leftrightarrow \\vv{w} \\leftarrow (1-\\epsilon \\alpha) \\vv{w} - \\epsilon \\nabla{J} $$L2正则化可以看成MAP Bayesian Estimation。假设损失函数\\(J(\\vv{\\theta}|\\vv{X},\\vv{Y})\\)为最大似然估计MLE(\\(-\\log P_\\text{model}(\\vv{\\theta}|\\vv{X},\\vv{Y})\\))，则在MAP中，若假设参数的先验分布为 \\[ \\vv{\\theta}\\sim\\mathcal{N}(\\vv{0}, \\frac{1}{\\alpha}\\mathbf{I}) \\] 则MAP估计得到损失函数为 \\[ \\hat{J}=-\\log{P_\\text{model}(\\vv{\\theta}|\\vv{X},\\vv{Y})}-\\log{P(\\vv{\\theta})}\\\\ =J+\\alpha \\vv{\\theta}^\\top\\vv{\\theta} \\]我们考虑一个简单的情况，损失函数是连续的二次函数，泰勒展开三阶及以上余项为0 \\[ \\vv{w}^*=\\text{argmin}_\\vv{w} J(\\vv{w})\\\\ \\Rightarrow J(\\vv{w})=J(\\vv{w}^*)+\\frac{1}{2}(\\vv{w}-\\vv{w}^*)^\\top\\mathbf{H}(\\vv{w}-\\vv{w}^*)\\\\ \\Rightarrow \\nabla \\hat J=\\mathbf{H}(\\vv{w}-\\vv{w}^*)+\\alpha\\vv{w} \\] 此时损失函数\\(\\hat J\\)的最优解应满足 \\[ \\tilde{\\vv{w}}=(\\mathbf{H}+\\alpha\\mathbf{I})^{-1}\\mathbf{H}\\vv{w}^* \\] 将\\(\\mathbf{H}\\)做正交对角化，得到 \\[ \\tilde{\\vv{w}}=\\mathbf{Q}(\\mathbf{\\Lambda}+\\alpha\\mathbf{I})^{-1}\\mathbf{\\Lambda}\\mathbf{Q}^\\top\\vv{w}^* \\] 考虑上式系数矩阵的特征值,\\(\\tilde{\\lambda_i}=\\frac{\\lambda_i}{\\lambda_i+\\alpha}\\)，我们发现特征值比较大的方向上，基本没有变化；特征值比较小的方向，则权重会减小。考虑最简单的情况，线性拟合，使用均方误差，则\\(\\vv{w}\\)有最优解： \\[ J=(\\mathbf{X}\\vv{w}-\\vv{y})^\\top(\\mathbf{X}\\vv{w}-\\vv{y}) \\\\ \\hat J = (\\mathbf{X}\\vv{w}-\\vv{y})^\\top(\\mathbf{X}\\vv{w}-\\vv{y})+\\frac{1}{2}\\alpha\\vv{w}^\\top\\vv{w} \\]此时的最优解分别为 \\[ \\boldsymbol w=(\\mathbf{X}\\mathbf{X}^\\top)^{-1}\\mathbf{X}^\\top\\boldsymbol w \\\\ \\hat{\\boldsymbol w}=(\\mathbf{X}\\mathbf{X}^\\top + \\alpha \\mathbf{I})^{-1}\\mathbf{X}^\\top\\boldsymbol w \\]L1 NormNorm Penalties as constrained optimazation将有范数惩罚项的优化目标看作有约束的最优化问题。Regularization and under-constrained problemsDataset augmentation通过数据增强增加泛化性能。对于神经网络，数据增强有着特别重要的意义。数据增强的一种方式就是对输入数据加入随机噪声。Dropout可以看作是一种数据增强方法。Noise Robustness一般加入噪声比只是约束参数的大小效果更好，尤其是在隐藏层加入噪声。另一种正则化模型的方法是给权重增加噪声。这对应的是模型权重的不确定性。给权重增加噪声可以使模型找到对权重变化不敏感的极小点。一些数据集label有错误。为了避免这种危害，可以直接对label的不确定性建模。比如在多分类问题中，softmax输出层的目标是0-1。可以设定一个label错误的概率\\(\\epsilon\\)，将目标改为\\((\\frac{\\epsilon}{k})\\)-\\((1-\\frac{\\epsilon}{k-1})\\)当目标是0-1的时候，softmax永远不可能学习到0-1，模型永远不会收敛，此时参数只是无限制地增大。我们也可以用其他正则化的方式，比如weight decay解决这个问题。Semi-Supervised LearningMulti-Task LearningEarly Stoppingimage-20190113144830928Early stopping可以看作是一种选择超参\"训练时间\"的方法使用验证集会导致有一部分训练集无法被模型使用。这时可以重新使用整个数据集进行训练。Early stopping的正则化作用机制是限制了参数的变化范围image-20190113154117157以线性回归为例，在适当的条件下early stopping和L2 norm regularization是等价的。但是early stopping相比weight decay有着不需要调整超参，只需要根据验证集上的误差就足够了。Parameter Trying，Parameter Sharing有时我们会希望限制模型中的参数互相之间比较接近。一种方式是加入显式的约束。\\(\\alpha ||\\boldsymbol w_a - \\boldsymbol w_b||_2\\)。实际上可以直接让这样的参数相等，这种方法就是parameter sharing。parameter sharing可以只存储一份参数，减少了内存开销。CNN就是parameter sharing的例子。Sparse Represetations参数的L1正则化会形成稀疏的模型：image-20190113160610461而这里我们希望得到稀疏的表示：image-20190113160630989可以仿照参数的L1正则化： \\[ \\tilde J=J+\\alpha \\Omega(\\boldsymbol h) \\] 或者使用orthogonal matching pursuit （OMP）显式地限制\\(\\boldsymbol h\\)为稀疏的： \\[ \\text{argmin}_{\\boldsymbol h, ||\\boldsymbol h||_0 &lt; k} ||\\boldsymbol x - \\mathbf{W} \\boldsymbol h||_2 \\]Bagging and Other Ensemble MethodBagging (short for bootstrap aggregating) is a technique for reducing generalization error by combining several modelson average, the ensemblewill perform at least as well as any of its members, and if the members makeindependent errors, the ensemble will perform signiﬁcantly better than its membersDropoutDropout的两种approximate方法：metro carlo，直接使用全部单元。后者计算开销几乎没有，但是性能两者在不同的问题互有上下。One of the key insights of dropout is that training a network with stochasticbehavior and making predictions by averaging over multiple stochastic decisionsimplements a form of bagging with parameter sharing对模型的随机改变并不局限于随机丢弃某些单元。例如将权重乘以一个随机变量也是有效的。Dropout的另一个作用：This means each hidden unit must be able to perform well regardless of which other hidden units are in the modelDropout thus regularizes each hidden unit to be not merely a good feature but a feature that is good in many contextsAdvertisial TrainingTangent Distance, Tangent Prop, and Manifold Tangent Classiﬁer","categories":[{"name":"DeepLearningBook","slug":"DeepLearningBook","permalink":"https://blog.lizeyan.me/categories/DeepLearningBook/"}],"tags":[]},{"title":"PC Algorithm","slug":"Algorithm/PC_algorithm","date":"2020-03-27T09:10:54.064Z","updated":"2020-03-27T09:10:54.064Z","comments":true,"path":"Algorithm/PC_algorithm/","link":"","permalink":"https://blog.lizeyan.me/Algorithm/PC_algorithm/","excerpt":"","text":"PC AlgorithmFind the Equivalence Class of a DAGConcepts and NotationsFaithfulness1A probability distribution \\(P\\) is said to be faithful with respect to a graph \\(G\\), if conditional independencies of the distribution can be inferred from d-seperation in the graph \\(G\\) and vice-visa. More precisely, consider a random vector \\(\\mathbf{X}\\sim P\\). Faithfulness of \\(P\\) with respect to \\(G\\) means, for any \\(i\\ne j\\in V\\) and any set \\(\\mathbf{s}\\in V\\),\\[ \\mathbf{X}^{(i)}\\bot \\mathbf{X}^{(j)}\\ \\text{given} \\ \\mathbf{s} \\\\\\leftrightarrow\\\\ i\\ \\text{and}\\ j \\text{are d-seperated by the set}\\ s \\]D-Seperation2The Bayes net assumption says, \"each variable is conditionally independent of its non-descendants, given its parents\".D-seperation is a formal procedure using this statement.Draw the ancestral graph.For each pair of variables with a common child, draw a undirected edge between them.Replace directed edges with undirected edges.Delete the givens and their edges.If the variables are disconnected, or one or more are missing, they are guaranteed to be independent. 'Connected' means there is a path between them, even though they are not directly connected:Example:image-20190715161555478A and B are not independent given D and F.A and B are marginally independent.A and B are not independent given C.D and E are independent given C.D and E are not marginally independent.D and E are not independent given A and B.Skeleton and V-StrutureThe skeleton of a DAG \\(G\\) is the undirected graph obtained from \\(G\\) by substudting undirected edges for directed edges.A v-structure is an ordered triple \\((i, j, k)\\) such that \\(G\\) contains \\(i\\to j\\) and \\(j\\to k\\) but no \\(i\\to k\\).EquivalentTwo DAG are equilavent if and only if they have the same skeleton and the san v-structures.Find The Skeleton Using PC Algorithm3image-20190715171557495Consider a DAG \\(G\\) and assume that the distribution \\(P\\) is faithful to \\(G\\). Denote the maximal number of neighbors by \\(q=\\max_{1\\le j\\le p}|adj(G, j)|\\). Thenm the \\(PC_{pop}\\) algorithm constructs the true skeleton of the DAG.Sample Version of PC algorithm4Kalisch, Markus, and Peter Bühlmann. \"Estimating high-dimensional directed acyclic graphs with the PC-algorithm.\" Journal of Machine Learning Research 8.Mar (2007): 613-636.↩http://web.mit.edu/jmn/www/6.034/d-separation.pdf↩Kalisch, Markus, and Peter Bühlmann. \"Estimating high-dimensional directed acyclic graphs with the PC-algorithm.\" Journal of Machine Learning Research 8.Mar (2007): 613-636.↩Kalisch, Markus, and Peter Bühlmann. \"Estimating high-dimensional directed acyclic graphs with the PC-algorithm.\" Journal of Machine Learning Research 8.Mar (2007): 613-636.↩","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.lizeyan.me/categories/Algorithm/"}],"tags":[]},{"title":"Association Rule Mining","slug":"Algorithm/association_rule_mining","date":"2020-03-27T09:10:54.064Z","updated":"2020-03-27T09:10:54.064Z","comments":true,"path":"Algorithm/association_rule_mining/","link":"","permalink":"https://blog.lizeyan.me/Algorithm/association_rule_mining/","excerpt":"","text":"Association Rule MiningAssociation rule mining can be viewed as a two-step process:Mining all frequent itemsets.Generate strong association rules from the frequent itemsets.A itemset X is closed if there is no proper super-set Y such that Y has the same support count as X.A itemset X is a closed frequent itemset if X is frequent and closed.A itemset X is a maximal frequent if X is frequent and there is no proper super-set Y such that Y is frequent.Frequent Itemset Mining MethodsAprioriGenerate candidates and test if they are frequent.The key is pruning the search space.The Apriori property: If a itemset is not frequent, then any superset of it is not frequent.The procedure of Apriori algorithm:generate length-\\(k\\) candidates based on length-\\((k-1)\\) frequent itemsets.Scan the database once and prune the infrequent length-\\(k\\) candidates.Improve the Efficiency of AprioriHash-based technique Hash the itemsets into buckets. If a candidate's corresponding bucket count is below the support threshold, then we need not to test it. It is especially useful when \\(k=2\\).Transaction reduction A transaction does not contain any length-\\(k\\) frequent itemset, cannot contain any length-\\((k+1)\\) frequent itemset.Partitioning Partition the search space into some subspaces. Any global frequent itemset must be local frequent itemset in at least one subspace (with support threshold in subspace changed)Sampling.Dynamic itemset countingFrequent-Pattern Grouwth","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.lizeyan.me/categories/Algorithm/"}],"tags":[]},{"title":"Locality Sensitive Hashing","slug":"Algorithm/locality_sensitive_hash","date":"2020-03-27T09:10:54.064Z","updated":"2020-03-27T09:10:54.064Z","comments":true,"path":"Algorithm/locality_sensitive_hash/","link":"","permalink":"https://blog.lizeyan.me/Algorithm/locality_sensitive_hash/","excerpt":"","text":"[TOC]Definition and InstancesLSH is a randomized hasing framework for efficient approximate neasrest negibot search in high dimensional space.It is based on the definition of LSH family \\(\\mathcal{H}\\), a family of hash functions mapping similar input items into the same hash code with higher probability than dissimilar items.LSH aims to maximize the probability of collision of similar items, while tradition hash always avoid collisions.The FamilyA family \\(\\mathcal{H}\\) is \\((R, cR, P_1, P_2)\\)-sensitive if for any two items \\(p\\) and \\(q\\)If \\(d(p, q)\\le R\\), then \\(P(h(p)=h(q))\\ge P_1​\\)If \\(d(p, q)\\ge cR\\), then \\(P(h(p)=h(q))\\le P_2\\)Here \\(c&gt;1\\), \\(P_1&gt;P_2\\), \\(h\\in\\mathcal{H}\\)Define \\(\\rho=\\frac{\\log P_1}{\\log P_2}\\), then there exists an algorithm for (R, C)-near neighbor problem which uses \\(O(dn+n^{1+\\rho})\\) space, with query time dominated by \\(O(n^{\\rho})\\) distance computations and \\(O(n^{\\rho}\\log_{1/P_2}n)\\) evaluations of hash functions. 1Define \\(g(x)=(h_1(x), ...., h_K(x))\\), the output of \\(g\\) identifies a hash bucket id.However, the compound hash function also reduce the probability of collsion of smiliar items.To improve the recall, \\(L\\) such compund hash function are sampled independently, each of which corresponds to a hash table.To improve precision, K should be large.To improve recall, L should be large.The items lying in the L hash buckets are retrieved as near item candidates.\\(l_p\\) DistanceAngle-Based DistanceHamming DistanceJaccard Coefficient\\(\\mathcal{X}^2\\) DistanceRank SimilarityShift Invariant KernelsNon-Metric DistanceArbitrary Distance MeasuresSearch, Modeling and AnalyzingSearchEntropy-based searchLSH forestAdaptative LSHMulti-Probe LSH 2Given a query \\(q\\), the basic LSH query \\(g(q)=(h_1(q), ..., h_M(q))\\), while multi-probe LSH probes \\(g(q)+\\Delta\\). \\(\\Delta=(\\delta_1, ..., \\delta_M), \\delta_i\\in\\{-1, 0, 1\\}\\), since similar objects should hash to the same or adjacent buckets with high probability. A approriate pertubation sequence will make multi-probe LSH achieves similar recall with less hash tables and similar time complexity.Step-Wise Probing SequenceFirstly probe the 1-step buckets, then all the 2-step buckets, and so on.The total number of all \\(n​\\)-step buckets is \\(L\\times {M\\choose n}\\times2^n​\\).image-20190525212643536Query-Directed Probing SequenceUsing the step-wise probing method, all coordinates in the hash values are treated identically. And the probability of adding 1 and substracting 1 from each coordinate is equal as well.image-20190525213133478Consider the hash function \\(h(q)=\\lfloor\\frac{a\\cdot q+b}{W}\\rfloor​\\).Let \\(x_i(\\delta)​\\) ne the distance of \\(q​\\) from the boundary of the slot \\(h_i(q)+\\delta​\\), then \\(x_i(-1)=f_i(q)-W\\cdot f_i(q)​\\), where \\(f_i(q)=a\\cdot q + b​\\). \\(x_i(1)=W-x_i(-1)​\\). And we define \\(x(0)=0​\\)For any fixed point \\(p\\), \\(f_i(p)-f_i(q)\\) is a Gaussian random variable (\\(a\\) is a sampled from a standard Gaussian), with 0 mean, and the variance is \\(||p-q||_2^2\\).image-20190525215318390Then it indicates that \\(score(\\Delta)=\\sum_{i=1}^{M}x_i(\\delta_i)^2\\). Pertutation vector with smaller score should have higher probability of yielding points near to \\(q\\).Then we firstly calculate \\(x_i(\\delta), i=1, 2, ..., M, \\delta\\in\\{-1,1\\}\\). We sort these \\(2M\\) valus in increasing order. Let \\(z_j\\) denote the \\(j\\)th element in this sorted order.Let \\(\\pi_j=(i, \\delta)\\) if \\(z_j=x_i(\\delta)\\). Since \\(x_i(-1)+x_i(1)=W\\), if \\(\\pi_j=(i, \\delta)\\), then \\(\\pi_{2M+1-j}=(i, -\\delta)\\).Then the problem reduces to the problem of generating perturbation sets in increasing order of their scores.image-20190526142038241image-20190526142045937Optimized Probing Sequence ConstructionTo avoid the overhead of maintaining the querying such a heap at query time, we precompute a certain sequence and reduce the generation of pertibation vectors to performing lookups instead of heap queries and updates.We approximate the \\(z_j^2\\) values by their expectations.Note that \\(x_i(\\delta)\\) is uniformly distributed in \\([0, W]\\), and \\(x_i(\\delta)+x_i(-\\delta)=W\\).The joint distribution of \\(z_j\\) for \\(j=1,2,...,M\\) is the following: pick \\(M\\) numbers uniformaly and at random from \\([0, \\frac{W}{2}]\\). \\(z_j\\) is the \\(j\\)-th largest nuber in this set. This is a well studied distribution. \\[ E[z_j]=\\frac{j}{2(M+1)}W\\\\ E[z_j^2]=\\frac{j(j+1)}{4(M+1)(M+2)}W^2 \\]Dynamic Collision Counting for Search 3Use dynamic compound hash function rather than a static one.C2LSH firstly randomly chooses a set of \\(m\\) LSDH functions with appropriately small interval \\(W\\), which form a function base \\(\\mathcal{B}​\\).Only data objects with large enough collison counts need to have their distances computed.Collision Number and Frequent ObjectA data object is called frequence if its collision number #collision(o) is greater than or equal to a pre-specified collision threshold l.LSH Functions for C2LSHLevel-1: \\(h(o)=\\lfloor\\frac{\\vec a \\cdot \\vec o + b^*}{W}\\rfloor\\), it is \\((1, c, p_1, p_2)\\) sensitive.Level-R hash function: \\(h^R(o)=\\lfloor\\frac{h(o)}{R}\\rfloor\\), it is \\((R, cR, p_1, p_2)\\)-sensitiveAn objects o's level-R bucket identified by the level-R bid, consists of R consecutive level-1 buckets identified by the level-1 bids.C2LSH for \\((R, c)\\)-NN SearchFristly calculate the buckets that \\(q\\) falls in by \\(h_i(q), i=1,2,...,m\\), and find the objects collides with \\(q\\).Then we compute #collides(o) for every \\(o\\) and hence identify the set \\(C\\) of all frequent objects. Then we compute \\(max(\\#C, \\beta n)\\) frequent members of C. \\(n\\) is the the cardinality of the database.Collison threshold: \\(l=\\alpha m\\)These two properties should hold to ensure C2LSH correct:\\(\\mathcal{P}_1\\): If there exists a data object o, s.t. \\(o\\in B(q, R)\\), then o's collison number is at least l.\\(\\mathcal{P}_2\\): The total number of false positives is less than \\(\\beta n​\\)image-20190526160936851C2LSH for c-Approxinate NN SearchVirtual RehashingGiven a query, object Q, there may not exist any data object within the ball centered at q with the radius \\(R=1\\). C2LSH then simulates the search of E2LSH at \\(1, c, c^2, ....\\)According to observation above, locating the level-c bucket is equivalent to locating c level-1 buckets.Neatest Neighbor Algorithmimage-20190526162845491Bayesian LSHFast LSHBi-Level LSHSortingKeys-LSHAnalysis and ModelingLocalitysensitive hashing scheme based on p-stable distributions.↩Q. Lv, W. Josephson, Z. Wang, M. Charikar, and K. Li. Multiprobe lsh: Efﬁcient indexing for high-dimensional similarity search. In VLDB, pages 950–961, 2007. 3, 8↩Gan, Junhao, et al. \"Locality-sensitive hashing scheme based on dynamic collision counting.\" Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data. ACM, 2012.↩","categories":[{"name":"Algorithm","slug":"Algorithm","permalink":"https://blog.lizeyan.me/categories/Algorithm/"}],"tags":[]},{"title":"Hexo Config","slug":"configuration/hexo_config","date":"2018-11-17T04:12:59.000Z","updated":"2020-03-27T09:10:54.112Z","comments":true,"path":"configuration/hexo_config/","link":"","permalink":"https://blog.lizeyan.me/configuration/hexo_config/","excerpt":"Hexo Config","text":"Hexo Config插入图片12npm install https://github.com/7ym0n/hexo-asset-image --savim node_modules/hexo-asset-image/index.js1234567var link = data.permalink;if(version.length &gt; 0 &amp;&amp; Number(version[0]) == 3) var beginPos = getPosition(link, '/', 4) + 1;else var beginPos = getPosition(link, '/', 3) + 1;// In hexo 3.1.1, the permalink of \"about\" page is like \".../about/index.html\".var endPos = link.lastIndexOf('/') + 1;数学公式https://nathaniel.blog/tutorials/make-hexo-support-math-again/Math Formulation\\[ \\int_\\mathbb{R}\\mu(dx) \\]Code12import pandas as pddf = pd.read_csv(path)Image testimage-20181117165546436","categories":[{"name":"configuration","slug":"configuration","permalink":"https://blog.lizeyan.me/categories/configuration/"}],"tags":[]}]}